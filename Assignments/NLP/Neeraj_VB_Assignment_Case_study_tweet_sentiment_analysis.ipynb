{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KXxnEwA-pWU2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rkhWFEwvpWU5",
        "outputId": "e34b5ff1-1023-4741-b48f-f8aed7773bd2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>What amazing service! Apple won't even talk to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7915</th>\n",
              "      <td>7916</td>\n",
              "      <td>0</td>\n",
              "      <td>Live out loud #lol #liveoutloud #selfie #smile...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7916</th>\n",
              "      <td>7917</td>\n",
              "      <td>0</td>\n",
              "      <td>We would like to wish you an amazing day! Make...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7917</th>\n",
              "      <td>7918</td>\n",
              "      <td>0</td>\n",
              "      <td>Helping my lovely 90 year old neighbor with he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>7919</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally got my #smart #pocket #wifi stay conne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>7920</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple Barcelona!!! #Apple #Store #BCN #Barcelo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7920 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  label                                              tweet\n",
              "0        1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
              "1        2      0  Finally a transparant silicon case ^^ Thanks t...\n",
              "2        3      0  We love this! Would you go? #talk #makememorie...\n",
              "3        4      0  I'm wired I know I'm George I was made that wa...\n",
              "4        5      1  What amazing service! Apple won't even talk to...\n",
              "...    ...    ...                                                ...\n",
              "7915  7916      0  Live out loud #lol #liveoutloud #selfie #smile...\n",
              "7916  7917      0  We would like to wish you an amazing day! Make...\n",
              "7917  7918      0  Helping my lovely 90 year old neighbor with he...\n",
              "7918  7919      0  Finally got my #smart #pocket #wifi stay conne...\n",
              "7919  7920      0  Apple Barcelona!!! #Apple #Store #BCN #Barcelo...\n",
              "\n",
              "[7920 rows x 3 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('tweets.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzLGCiaSpWU5",
        "outputId": "2879d6b9-ffe6-4935-ef44-4b0b6cf34f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7920 entries, 0 to 7919\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      7920 non-null   int64 \n",
            " 1   label   7920 non-null   int64 \n",
            " 2   tweet   7920 non-null   object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 185.8+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPA19ySSpWU6",
        "outputId": "970f60f5-3caa-49c5-a4fe-2666785d7ea8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    5894\n",
              "1    2026\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0TuBQRzpWU6",
        "outputId": "c77c6d44-91ca-4810-aab3-5e09939222c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id       0\n",
              "label    0\n",
              "tweet    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tweets preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HWdSPno1pWU6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "import unidecode\n",
        "from nltk.tokenize.toktok import ToktokTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"I'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\^^\", \"\", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XMyTyfInpWU6"
      },
      "outputs": [],
      "source": [
        "def clean_keywords(word):\n",
        "    return re.sub(r'%20', ' ', word)\n",
        "def to_lowercase(word):\n",
        "    return word.lower()\n",
        "def remove_accents(word):\n",
        "    return unidecode.unidecode(word)\n",
        "def remove_punctuation(word):\n",
        "    return re.sub(r\"[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n -' ]\",\" \",word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H4epQEB0pWU7"
      },
      "outputs": [],
      "source": [
        "def cleaning_URLs(word):\n",
        "    return re.sub('((www.[^s]+)|(https?:\\/\\/.*?[\\s+]))',' ',word)\n",
        "def remove_mentions(word):\n",
        "    return re.sub('@[\\w]*',' ',word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Setting English stopwords\n",
        "tokenizer1 = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "#removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer1.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Removing all hyperlinks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['cleaned_tweet'] = df['tweet'].apply(lambda x: cleaning_URLs(x))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Removing and replacing certain patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['cleaned_tweet'] = df['cleaned_tweet'].apply(lambda x: remove_special_characters(x))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Removing @mentions of users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['cleaned_tweet'] = df['cleaned_tweet'].apply(lambda x: remove_mentions(x))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Removing all special characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['cleaned_tweet'] = df['cleaned_tweet'].apply(lambda x: remove_punctuation(x))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Converting everything to unicode characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['cleaned_tweet'] = df['cleaned_tweet'].apply(lambda x: remove_accents(x))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert everything to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['cleaned_tweet'] = df['cleaned_tweet'].apply(lambda x: to_lowercase(x))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Removing stopwords using NLTK corpus library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['final_cleaned_tweet'] = df['cleaned_tweet'].apply(lambda x: remove_stopwords(x, True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "      <th>final_cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
              "      <td>fingerprint pregnancy test android apps beauti...</td>\n",
              "      <td>fingerprint pregnancy test android apps beauti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
              "      <td>finally a transparant silicon case     thanks ...</td>\n",
              "      <td>finally transparant silicon case thanks uncle ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
              "      <td>we love this would you go talk makememories un...</td>\n",
              "      <td>love would go talk makememories unplug relax i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
              "      <td>im wired i know im george i was made that way ...</td>\n",
              "      <td>im wired know im george made way iphone cute d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>What amazing service! Apple won't even talk to...</td>\n",
              "      <td>what amazing service apple wont even talk to m...</td>\n",
              "      <td>amazing service apple wont even talk question ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7915</th>\n",
              "      <td>7916</td>\n",
              "      <td>0</td>\n",
              "      <td>Live out loud #lol #liveoutloud #selfie #smile...</td>\n",
              "      <td>live out loud lol liveoutloud selfie smile son...</td>\n",
              "      <td>live loud lol liveoutloud selfie smile sony mu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7916</th>\n",
              "      <td>7917</td>\n",
              "      <td>0</td>\n",
              "      <td>We would like to wish you an amazing day! Make...</td>\n",
              "      <td>we would like to wish you an amazing day make ...</td>\n",
              "      <td>would like wish amazing day make every minute ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7917</th>\n",
              "      <td>7918</td>\n",
              "      <td>0</td>\n",
              "      <td>Helping my lovely 90 year old neighbor with he...</td>\n",
              "      <td>helping my lovely 90 year old neighbor with he...</td>\n",
              "      <td>helping lovely 90 year old neighbor ipad morni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>7919</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally got my #smart #pocket #wifi stay conne...</td>\n",
              "      <td>finally got my smart pocket wifi stay connecte...</td>\n",
              "      <td>finally got smart pocket wifi stay connected a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>7920</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple Barcelona!!! #Apple #Store #BCN #Barcelo...</td>\n",
              "      <td>apple barcelona apple store bcn barcelona trav...</td>\n",
              "      <td>apple barcelona apple store bcn barcelona trav...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7920 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  label                                              tweet  \\\n",
              "0        1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...   \n",
              "1        2      0  Finally a transparant silicon case ^^ Thanks t...   \n",
              "2        3      0  We love this! Would you go? #talk #makememorie...   \n",
              "3        4      0  I'm wired I know I'm George I was made that wa...   \n",
              "4        5      1  What amazing service! Apple won't even talk to...   \n",
              "...    ...    ...                                                ...   \n",
              "7915  7916      0  Live out loud #lol #liveoutloud #selfie #smile...   \n",
              "7916  7917      0  We would like to wish you an amazing day! Make...   \n",
              "7917  7918      0  Helping my lovely 90 year old neighbor with he...   \n",
              "7918  7919      0  Finally got my #smart #pocket #wifi stay conne...   \n",
              "7919  7920      0  Apple Barcelona!!! #Apple #Store #BCN #Barcelo...   \n",
              "\n",
              "                                          cleaned_tweet  \\\n",
              "0     fingerprint pregnancy test android apps beauti...   \n",
              "1     finally a transparant silicon case     thanks ...   \n",
              "2     we love this would you go talk makememories un...   \n",
              "3     im wired i know im george i was made that way ...   \n",
              "4     what amazing service apple wont even talk to m...   \n",
              "...                                                 ...   \n",
              "7915  live out loud lol liveoutloud selfie smile son...   \n",
              "7916  we would like to wish you an amazing day make ...   \n",
              "7917  helping my lovely 90 year old neighbor with he...   \n",
              "7918  finally got my smart pocket wifi stay connecte...   \n",
              "7919  apple barcelona apple store bcn barcelona trav...   \n",
              "\n",
              "                                    final_cleaned_tweet  \n",
              "0     fingerprint pregnancy test android apps beauti...  \n",
              "1     finally transparant silicon case thanks uncle ...  \n",
              "2     love would go talk makememories unplug relax i...  \n",
              "3     im wired know im george made way iphone cute d...  \n",
              "4     amazing service apple wont even talk question ...  \n",
              "...                                                 ...  \n",
              "7915  live loud lol liveoutloud selfie smile sony mu...  \n",
              "7916  would like wish amazing day make every minute ...  \n",
              "7917  helping lovely 90 year old neighbor ipad morni...  \n",
              "7918  finally got smart pocket wifi stay connected a...  \n",
              "7919  apple barcelona apple store bcn barcelona trav...  \n",
              "\n",
              "[7920 rows x 5 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bag of Words model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "bow_model = CountVectorizer(stop_words=\"english\", ngram_range=(1,1))\n",
        "bow_vector = bow_model.fit_transform(df['final_cleaned_tweet']).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>00000</th>\n",
              "      <th>002</th>\n",
              "      <th>004</th>\n",
              "      <th>0051</th>\n",
              "      <th>007</th>\n",
              "      <th>008</th>\n",
              "      <th>01</th>\n",
              "      <th>010111</th>\n",
              "      <th>0101am</th>\n",
              "      <th>...</th>\n",
              "      <th>zs</th>\n",
              "      <th>zsofimonster</th>\n",
              "      <th>ztjeq</th>\n",
              "      <th>zumies</th>\n",
              "      <th>zune</th>\n",
              "      <th>zunehd</th>\n",
              "      <th>zurich</th>\n",
              "      <th>zv7tuur</th>\n",
              "      <th>zw1ck</th>\n",
              "      <th>zx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21278 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   000  00000  002  004  0051  007  008  01  010111  0101am  ...  zs  \\\n",
              "0    0      0    0    0     0    0    0   0       0       0  ...   0   \n",
              "1    0      0    0    0     0    0    0   0       0       0  ...   0   \n",
              "2    0      0    0    0     0    0    0   0       0       0  ...   0   \n",
              "3    0      0    0    0     0    0    0   0       0       0  ...   0   \n",
              "4    0      0    0    0     0    0    0   0       0       0  ...   0   \n",
              "\n",
              "   zsofimonster  ztjeq  zumies  zune  zunehd  zurich  zv7tuur  zw1ck  zx  \n",
              "0             0      0       0     0       0       0        0      0   0  \n",
              "1             0      0       0     0       0       0        0      0   0  \n",
              "2             0      0       0     0       0       0        0      0   0  \n",
              "3             0      0       0     0       0       0        0      0   0  \n",
              "4             0      0       0     0       0       0        0      0   0  \n",
              "\n",
              "[5 rows x 21278 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bow_df = pd.DataFrame(bow_vector)\n",
        "bow_df.columns = sorted(bow_model.vocabulary_)\n",
        "bow_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(bow_df, df['label'], test_size=0.15, random_state=134)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of Bag of words model using logistic regression: 88.05%\n"
          ]
        }
      ],
      "source": [
        "bow_log = LogisticRegression(fit_intercept=False)\n",
        "bow_log.fit(x_train, y_train)\n",
        "y_pred_bow_log = bow_log.predict(x_test)\n",
        "print(\"Accuracy score of Bag of words model using logistic regression: \" + str(round(accuracy_score(y_test, y_pred_bow_log) * 100, 2)) + \"%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of Bag of words model using Decision Tree Classifier: 85.69%\n"
          ]
        }
      ],
      "source": [
        "bow_dt = DecisionTreeClassifier()\n",
        "bow_dt.fit(x_train, y_train)\n",
        "y_pred_bow_dt = bow_dt.predict(x_test)\n",
        "print(\"Accuracy score of Bag of words model using Decision Tree Classifier: \" + str(round(accuracy_score(y_test, y_pred_bow_dt) * 100, 2)) + \"%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of Bag of words model using Gaussian Naive Bayes: 79.21%\n"
          ]
        }
      ],
      "source": [
        "bow_gnb = GaussianNB()\n",
        "bow_gnb.fit(x_train, y_train)\n",
        "y_pred_bow_gnb = bow_gnb.predict(x_test)\n",
        "print(\"Accuracy score of Bag of words model using Gaussian Naive Bayes: \" + str(round(accuracy_score(y_test, y_pred_bow_gnb) * 100, 2)) + \"%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TFIDF Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "tdfif_dense = tfidf.fit_transform(df['final_cleaned_tweet']).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>21424</th>\n",
              "      <th>21425</th>\n",
              "      <th>21426</th>\n",
              "      <th>21427</th>\n",
              "      <th>21428</th>\n",
              "      <th>21429</th>\n",
              "      <th>21430</th>\n",
              "      <th>21431</th>\n",
              "      <th>21432</th>\n",
              "      <th>21433</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7915</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7916</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7917</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7920 rows × 21434 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0      1      2      3      4      5      6      7      8      9      \\\n",
              "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "7915    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "7916    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "7917    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "7918    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "7919    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "      ...  21424  21425  21426  21427  21428  21429  21430  21431  21432  \\\n",
              "0     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "1     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "2     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "3     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "4     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "7915  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "7916  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "7917  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "7918  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "7919  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "      21433  \n",
              "0       0.0  \n",
              "1       0.0  \n",
              "2       0.0  \n",
              "3       0.0  \n",
              "4       0.0  \n",
              "...     ...  \n",
              "7915    0.0  \n",
              "7916    0.0  \n",
              "7917    0.0  \n",
              "7918    0.0  \n",
              "7919    0.0  \n",
              "\n",
              "[7920 rows x 21434 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_df = pd.DataFrame(tdfif_dense)\n",
        "tfidf_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(tfidf_df, df['label'], test_size=0.15, random_state=134)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of TFIDF model using logistic regression: 88.13%\n"
          ]
        }
      ],
      "source": [
        "tfidf_log = LogisticRegression(fit_intercept=False)\n",
        "tfidf_log.fit(x_train, y_train)\n",
        "y_pred_tfidf_log = tfidf_log.predict(x_test)\n",
        "print(\"Accuracy score of TFIDF model using logistic regression: \" + str(round(accuracy_score(y_test, y_pred_tfidf_log) * 100, 2)) + \"%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of TFIDF model using Decision Tree Classifier: 83.67%\n"
          ]
        }
      ],
      "source": [
        "tfidf_dt = DecisionTreeClassifier()\n",
        "tfidf_dt.fit(x_train, y_train)\n",
        "y_pred_tfidf_dt = tfidf_dt.predict(x_test)\n",
        "print(\"Accuracy score of TFIDF model using Decision Tree Classifier: \" + str(round(accuracy_score(y_test, y_pred_tfidf_dt) * 100, 2)) + \"%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of TFIDF model using Gaussian Naive Bayes: 79.38%\n"
          ]
        }
      ],
      "source": [
        "tfidf_gnb = GaussianNB()\n",
        "tfidf_gnb.fit(x_train, y_train)\n",
        "y_pred_tfidf_gnb = tfidf_gnb.predict(x_test)\n",
        "print(\"Accuracy score of TFIDF model using Gaussian Naive Bayes: \" + str(round(accuracy_score(y_test, y_pred_tfidf_gnb) * 100, 2)) + \"%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Word Embeddings Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "b9Hs93C7qji9"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec as wtv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6DCejAtEq5zI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       [fingerprint, pregnancy, test, android, apps, ...\n",
              "1       [finally, a, transparant, silicon, case, thank...\n",
              "2       [we, love, this, would, you, go, talk, makemem...\n",
              "3       [im, wired, i, know, im, george, i, was, made,...\n",
              "4       [what, amazing, service, apple, wont, even, ta...\n",
              "                              ...                        \n",
              "7915    [live, out, loud, lol, liveoutloud, selfie, sm...\n",
              "7916    [we, would, like, to, wish, you, an, amazing, ...\n",
              "7917    [helping, my, lovely, 90, year, old, neighbor,...\n",
              "7918    [finally, got, my, smart, pocket, wifi, stay, ...\n",
              "7919    [apple, barcelona, apple, store, bcn, barcelon...\n",
              "Name: cleaned_tweet, Length: 7920, dtype: object"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessed_text = df['cleaned_tweet'].apply(lambda x: x.split())\n",
        "preprocessed_text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating Cbow & skipgram models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "sErfPP4sql0T"
      },
      "outputs": [],
      "source": [
        "cbow_w2v_model = wtv(preprocessed_text, vector_size=800, window=5, min_count=3, sg=0)\n",
        "skgram_w2v_model = wtv(preprocessed_text, vector_size=800, window=5, min_count=3, sg=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg7o2FBLrl6k",
        "outputId": "a6528df6-ff08-4601-956c-7829bf993216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cbow vocabulary size: 4153\n",
            "skipgram vocabulary size: 4153\n"
          ]
        }
      ],
      "source": [
        "print(\"cbow vocabulary size:\", len(cbow_w2v_model.wv.index_to_key))\n",
        "print(\"skipgram vocabulary size:\", len(skgram_w2v_model.wv.index_to_key))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to return average word embedding vector value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "fAJ1FRThr9s9"
      },
      "outputs": [],
      "source": [
        "def get_embedding_w2v(doc_tokens, model):\n",
        "    embeddings = []\n",
        "    for tok in doc_tokens:\n",
        "      if tok in model.wv.index_to_key:\n",
        "          embeddings.append(model.wv.get_vector(tok))\n",
        "    return np.mean(embeddings, axis=0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UYug3hZUvHVG"
      },
      "source": [
        "### Skipgram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "AJPAH-6FvNme"
      },
      "outputs": [],
      "source": [
        "X_x2v_model = preprocessed_text.apply(lambda x: get_embedding_w2v(x, skgram_w2v_model))\n",
        "X_df_sg = pd.DataFrame(X_x2v_model.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ksqwUeY3pWU9"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_df_sg, df['label'], test_size=0.15, random_state=134)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "3yzta6eJpWU_",
        "outputId": "2e2818dc-87b3-4281-ef6c-bdfbd557e7b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of Skipgram model using logistic regression: 87.71%\n"
          ]
        }
      ],
      "source": [
        "sg_log = LogisticRegression(fit_intercept=False)\n",
        "sg_log.fit(x_train, y_train)\n",
        "y_pred_sg_log = sg_log.predict(x_test)\n",
        "print(\"Accuracy score of Skipgram model using logistic regression: \" + str(round(accuracy_score(y_test, y_pred_sg_log) * 100, 2)) + \"%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Decision tree classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of Skipgram model using Decision Tree Classifier: 83.25%\n"
          ]
        }
      ],
      "source": [
        "sg_dt = DecisionTreeClassifier()\n",
        "sg_dt.fit(x_train, y_train)\n",
        "y_pred_sg_dt = sg_dt.predict(x_test)\n",
        "print(\"Accuracy score of Skipgram model using Decision Tree Classifier: \" + str(round(accuracy_score(y_test, y_pred_sg_dt) * 100, 2)) + \"%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of Skipgram model using Gaussian Naive Bayes: 82.58%\n"
          ]
        }
      ],
      "source": [
        "sg_gnb = GaussianNB()\n",
        "sg_gnb.fit(x_train, y_train)\n",
        "y_pred_sg_gnb = sg_gnb.predict(x_test)\n",
        "print(\"Accuracy score of Skipgram model using Gaussian Naive Bayes: \" + str(round(accuracy_score(y_test, y_pred_sg_gnb) * 100, 2)) + \"%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nbh82TxvZGD"
      },
      "source": [
        "### Cbow model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "pwYgiqjPvYo0"
      },
      "outputs": [],
      "source": [
        "X_x2v_model = preprocessed_text.apply(lambda x: get_embedding_w2v(x, cbow_w2v_model))\n",
        "X_df_cbow = pd.DataFrame(X_x2v_model.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "pEVUf1VfvtCz"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_df_cbow, df['label'], test_size=0.15, random_state=134)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "u7TA_QU2vs36",
        "outputId": "62d30737-f613-4e9c-a2e2-fd74090e280e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of Cbow model using logistic regression: 84.34%\n"
          ]
        }
      ],
      "source": [
        "cbow_log = LogisticRegression(fit_intercept=False)\n",
        "cbow_log.fit(x_train, y_train)\n",
        "y_pred_cbow_log = cbow_log.predict(x_test)\n",
        "print(\"Accuracy score of Cbow model using logistic regression: \" + str(round(accuracy_score(y_test, y_pred_cbow_log) * 100, 2)) + \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAJILltJvxmX",
        "outputId": "0506035c-a3d3-4255-a29e-12cc836fc4bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of Cbow model using Decision Tree Classifier: 79.97%\n"
          ]
        }
      ],
      "source": [
        "cbow_dt = DecisionTreeClassifier()\n",
        "cbow_dt.fit(x_train, y_train)\n",
        "y_pred_cbow_dt = cbow_dt.predict(x_test)\n",
        "print(\"Accuracy score of Cbow model using Decision Tree Classifier: \" + str(round(accuracy_score(y_test, y_pred_cbow_dt) * 100, 2)) + \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NZL-tU_v0BB",
        "outputId": "689b8859-da83-4e4e-a996-45235772f569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of Cbow model using Gaussian Naive Bayes: 76.68%\n"
          ]
        }
      ],
      "source": [
        "cbow_gnb = GaussianNB()\n",
        "cbow_gnb.fit(x_train, y_train)\n",
        "y_pred_cbow_gnb = cbow_gnb.predict(x_test)\n",
        "print(\"Accuracy score of Cbow model using Gaussian Naive Bayes: \" + str(round(accuracy_score(y_test, y_pred_cbow_gnb) * 100, 2)) + \"%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = ((y_pred_bow_log, y_pred_bow_dt, y_pred_bow_gnb),\n",
        "           (y_pred_tfidf_log, y_pred_tfidf_dt, y_pred_tfidf_gnb),\n",
        "           (y_pred_sg_log, y_pred_sg_dt, y_pred_sg_gnb),\n",
        "           (y_pred_cbow_log, y_pred_cbow_dt, y_pred_cbow_gnb))\n",
        "\n",
        "rounded_accuracy_scores = []\n",
        "for item in predictions:\n",
        "    temp = []\n",
        "    for val in item:\n",
        "        temp.append(round(accuracy_score(y_test, val) * 100, 2))\n",
        "    rounded_accuracy_scores.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "algorithms = (\"Logistic Regression\", \"Decision Tree\", \"Naive Bayes\")\n",
        "models = (\"Bag of Words\", \"TFIDF\", \"Skipgram\", \"Cbow\")\n",
        "\n",
        "results_df = pd.DataFrame(rounded_accuracy_scores, columns=algorithms)\n",
        "results_df['models'] = models\n",
        "results_df.insert(0, 'models', results_df.pop(\"models\"))\n",
        "results_df.set_index('models', inplace=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy scores dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Naive Bayes</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>models</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bag of Words</th>\n",
              "      <td>88.05</td>\n",
              "      <td>85.69</td>\n",
              "      <td>79.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TFIDF</th>\n",
              "      <td>88.13</td>\n",
              "      <td>83.67</td>\n",
              "      <td>79.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skipgram</th>\n",
              "      <td>87.71</td>\n",
              "      <td>83.25</td>\n",
              "      <td>82.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cbow</th>\n",
              "      <td>84.34</td>\n",
              "      <td>79.97</td>\n",
              "      <td>76.68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Logistic Regression  Decision Tree  Naive Bayes\n",
              "models                                                       \n",
              "Bag of Words                88.05          85.69        79.21\n",
              "TFIDF                       88.13          83.67        79.38\n",
              "Skipgram                    87.71          83.25        82.58\n",
              "Cbow                        84.34          79.97        76.68"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From the data the TFIDF and Bag of words models trained using Logistic Regression gives the best accuracy"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
