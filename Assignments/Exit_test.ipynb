{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "BBOjnwzswje6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "pd.options.display.max_colwidth = 200"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('tweet_emotions .csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6zDwSse_wyAe",
        "outputId": "eed10912-0306-4a0f-bac0-444bf2f211b4"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     tweet_id   sentiment  \\\n",
              "0  1956967341       empty   \n",
              "1  1956967666     sadness   \n",
              "2  1956967696     sadness   \n",
              "3  1956967789  enthusiasm   \n",
              "4  1956968416     neutral   \n",
              "\n",
              "                                                                                        content  \n",
              "0  @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[  \n",
              "1                                  Layin n bed with a headache  ughhhh...waitin on your call...  \n",
              "2                                                           Funeral ceremony...gloomy friday...  \n",
              "3                                                          wants to hang out with friends SOON!  \n",
              "4        @dannycastillo We want to trade with someone who has Houston tickets, but no one will.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73f4c1fe-5326-477a-bd83-0e86e7392141\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1956967341</td>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1956967789</td>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1956968416</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73f4c1fe-5326-477a-bd83-0e86e7392141')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73f4c1fe-5326-477a-bd83-0e86e7392141 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73f4c1fe-5326-477a-bd83-0e86e7392141');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "tsZ3TQHszFaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh825gfpy-6C",
        "outputId": "f2cabbe5-cdb7-406d-9eff-a95cf7fe60df"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40000 entries, 0 to 39999\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   tweet_id   40000 non-null  int64 \n",
            " 1   sentiment  40000 non-null  object\n",
            " 2   content    40000 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 937.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5slUh9Cy5rT",
        "outputId": "3fbf29fb-2445-46ad-f841-e5510df74c1c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_id     0\n",
              "sentiment    0\n",
              "content      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xXBdzmWzD4S",
        "outputId": "5438df7c-3869-48d2-d047-621b4d886eff"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "boredom        179\n",
              "anger          110\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_count = df['sentiment'].nunique()\n",
        "emotion_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75TivmdsOSFu",
        "outputId": "e3a66e5d-d6ec-45c2-81d6-753998c40340"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a total of 13 emotions to process"
      ],
      "metadata": {
        "id": "Vv0speabsZLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "av9zsJVjzgUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['tweet_id'], inplace=True) # No valuable information"
      ],
      "metadata": {
        "id": "6Nbwwf5Ny8wD"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "D0EjnRbrzlZA"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df['sentiment'] = le.fit_transform(df['sentiment']) # encoding sentiments to numeric values"
      ],
      "metadata": {
        "id": "B8QP50gLy2-b"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting to dictionaries for future conversions"
      ],
      "metadata": {
        "id": "K2MMXYmesP8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_index = {i: label for i, label in zip(le.classes_, range(0, len(le.classes_)))}\n",
        "index_to_class = {label: i for i, label in class_to_index.items()}\n",
        "class_to_index, index_to_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KusIVh6Z09mC",
        "outputId": "ff380bf1-3277-4fa3-9b4d-f6eaa1c83b88"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'anger': 0,\n",
              "  'boredom': 1,\n",
              "  'empty': 2,\n",
              "  'enthusiasm': 3,\n",
              "  'fun': 4,\n",
              "  'happiness': 5,\n",
              "  'hate': 6,\n",
              "  'love': 7,\n",
              "  'neutral': 8,\n",
              "  'relief': 9,\n",
              "  'sadness': 10,\n",
              "  'surprise': 11,\n",
              "  'worry': 12},\n",
              " {0: 'anger',\n",
              "  1: 'boredom',\n",
              "  2: 'empty',\n",
              "  3: 'enthusiasm',\n",
              "  4: 'fun',\n",
              "  5: 'happiness',\n",
              "  6: 'hate',\n",
              "  7: 'love',\n",
              "  8: 'neutral',\n",
              "  9: 'relief',\n",
              "  10: 'sadness',\n",
              "  11: 'surprise',\n",
              "  12: 'worry'})"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "weI9FSPO59DB",
        "outputId": "99e5bb4f-3d2a-4060-cb5b-8d70b3a561da"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sentiment  \\\n",
              "0              2   \n",
              "1             10   \n",
              "2             10   \n",
              "3              3   \n",
              "4              8   \n",
              "...          ...   \n",
              "39995          8   \n",
              "39996          7   \n",
              "39997          7   \n",
              "39998          5   \n",
              "39999          7   \n",
              "\n",
              "                                                                                                                                    content  \n",
              "0                                              @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[  \n",
              "1                                                                              Layin n bed with a headache  ughhhh...waitin on your call...  \n",
              "2                                                                                                       Funeral ceremony...gloomy friday...  \n",
              "3                                                                                                      wants to hang out with friends SOON!  \n",
              "4                                                    @dannycastillo We want to trade with someone who has Houston tickets, but no one will.  \n",
              "...                                                                                                                                     ...  \n",
              "39995                                                                                                                      @JohnLloydTaylor  \n",
              "39996                                                                                                        Happy Mothers Day  All my love  \n",
              "39997           Happy Mother's Day to all the mommies out there, be you woman or man as long as you're 'momma' to someone this is your day!  \n",
              "39998            @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEEP OUT MY NEW HIT SINGLES WWW.MYSPACE.COM/IPSOHOT I DEF. WAT U IN THE VIDEO!!  \n",
              "39999  @mopedronin bullet train from tokyo    the gf and i have been visiting japan since thursday  vacation/sightseeing    gaijin godzilla  \n",
              "\n",
              "[40000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17bca840-c990-45bc-809e-3283a4cf0f70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39995</th>\n",
              "      <td>8</td>\n",
              "      <td>@JohnLloydTaylor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39996</th>\n",
              "      <td>7</td>\n",
              "      <td>Happy Mothers Day  All my love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39997</th>\n",
              "      <td>7</td>\n",
              "      <td>Happy Mother's Day to all the mommies out there, be you woman or man as long as you're 'momma' to someone this is your day!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39998</th>\n",
              "      <td>5</td>\n",
              "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEEP OUT MY NEW HIT SINGLES WWW.MYSPACE.COM/IPSOHOT I DEF. WAT U IN THE VIDEO!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39999</th>\n",
              "      <td>7</td>\n",
              "      <td>@mopedronin bullet train from tokyo    the gf and i have been visiting japan since thursday  vacation/sightseeing    gaijin godzilla</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17bca840-c990-45bc-809e-3283a4cf0f70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17bca840-c990-45bc-809e-3283a4cf0f70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17bca840-c990-45bc-809e-3283a4cf0f70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DtjBiI05n4q",
        "outputId": "ac708c3c-f7f5-4425-b100-ed0017da3091"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unidecode\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-Yn4VdX04AW",
        "outputId": "6373f236-6bcf-4a62-c716-cdbd356fb46a"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    #Removing URLs\n",
        "    text = re.sub('((www.[^s]+)|(https?:\\/\\/.*?[\\s+]))',' ', text)\n",
        "    #Removing mentions\n",
        "    text = re.sub('@[\\w]*',' ', text)\n",
        "\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'\\.{2,}', ' ', text)\n",
        "    text = re.sub(r',+', ', ', text)\n",
        "    text = re.sub(r'[^A-Za-zÀ-ú ]+', '', text)\n",
        "    # Convert to lower case\n",
        "    text = text.lower()\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = unidecode.unidecode(text)  # removing accents\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(texto):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = nltk.word_tokenize(texto.lower())\n",
        "    return \" \".join([token for token in tokens if token not in stop_words])\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def simple_lemmatizer(text):\n",
        "    text= ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "    return text"
      ],
      "metadata": {
        "id": "0_Kp0DgE5X5m"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['content_clean'] = df['content'].apply(clean_text)\n",
        "df['content_clean'] = df['content_clean'].apply(remove_stopwords)   # removing stopwords\n",
        "df['content_clean'] = df['content_clean'].apply(simple_lemmatizer)  # applying word lemmatizer for consistency"
      ],
      "metadata": {
        "id": "AY9EGbU66oNd"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XsOmF3i47fho",
        "outputId": "50843988-c292-481e-80c6-b149678dae7e"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sentiment  \\\n",
              "0           2   \n",
              "1          10   \n",
              "2          10   \n",
              "3           3   \n",
              "4           8   \n",
              "5          12   \n",
              "6          10   \n",
              "7          12   \n",
              "8          10   \n",
              "9          10   \n",
              "10          8   \n",
              "11         12   \n",
              "12         10   \n",
              "13         10   \n",
              "14         11   \n",
              "15         10   \n",
              "16          7   \n",
              "17         10   \n",
              "18         12   \n",
              "19         10   \n",
              "20         12   \n",
              "21          4   \n",
              "22          8   \n",
              "23         12   \n",
              "24         10   \n",
              "25         12   \n",
              "26         10   \n",
              "27         12   \n",
              "28         10   \n",
              "29         12   \n",
              "\n",
              "                                                                                                                                       content  \\\n",
              "0                                                 @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[   \n",
              "1                                                                                 Layin n bed with a headache  ughhhh...waitin on your call...   \n",
              "2                                                                                                          Funeral ceremony...gloomy friday...   \n",
              "3                                                                                                         wants to hang out with friends SOON!   \n",
              "4                                                       @dannycastillo We want to trade with someone who has Houston tickets, but no one will.   \n",
              "5                                                         Re-pinging @ghostridah14: why didn't you go to prom? BC my bf didn't like my friends   \n",
              "6         I should be sleep, but im not! thinking about an old friend who I want. but he's married now. damn, &amp; he wants me 2! scandalous!   \n",
              "7                                                                                                         Hmmm. http://www.djhero.com/ is down   \n",
              "8                                                                                                      @charviray Charlene my love. I miss you   \n",
              "9                                                                                                   @kelcouch I'm sorry  at least it's Friday?   \n",
              "10                                                                                                                            cant fall asleep   \n",
              "11                                                                                                                     Choked on her retainers   \n",
              "12                                                                              Ugh! I have to beat this stupid song to get to the next  rude!   \n",
              "13  @BrodyJenner if u watch the hills in london u will realise what tourture it is because were weeks and weeks late  i just watch itonlinelol   \n",
              "14                                                                                                                                Got the news   \n",
              "15                                                                                               The storm is here and the electricity is gone   \n",
              "16                                                                                                                        @annarosekerr agreed   \n",
              "17                                                                             So sleepy again and it's not even that late. I fail once again.   \n",
              "18                                              @PerezHilton lady gaga tweeted about not being impressed by her video leaking just so you know   \n",
              "19                  How are YOU convinced that I have always wanted you? What signals did I give off...damn I think I just lost another friend   \n",
              "20                                                      @raaaaaaek oh too bad! I hope it gets better. I've been having sleep issues lately too   \n",
              "21                   Wondering why I'm awake at 7am,writing a new song,plotting my evil secret plots muahahaha...oh damn it,not secret anymore   \n",
              "22                    No Topic Maps talks at the Balisage Markup Conference 2009   Program online at http://tr.im/mL6Z (via @bobdc) #topicmaps   \n",
              "23                                                          I ate Something I don't know what it is... Why do I keep Telling things about food   \n",
              "24                                so tired and i think i'm definitely going to get an ear infection.  going to bed &quot;early&quot; for once.   \n",
              "25                      On my way home n having 2 deal w underage girls drinking gin on da bus while talking bout keggers......damn i feel old   \n",
              "26                 @IsaacMascote  i'm sorry people are so rude to you, isaac, they should get some manners and know better than to be so lewd!   \n",
              "27                                                                    Damm servers still down  i need to hit 80 before all the koxpers pass me   \n",
              "28                                      Fudge.... Just BS'd that whole paper.... So tired.... Ugh I hate school.....  time to sleep!!!!!!!!!!!   \n",
              "29                                                                                               I HATE CANCER. I HATE IT I HATE IT I HATE IT.   \n",
              "\n",
              "                                                                                     content_clean  \n",
              "0                                             know listenin bad habit earlier started freakin part  \n",
              "1                                                          layin n bed headache ughhhh waitin call  \n",
              "2                                                                   funeral ceremony gloomy friday  \n",
              "3                                                                            want hang friend soon  \n",
              "4                                                            want trade someone houston ticket one  \n",
              "5                                                  repinging didnt go prom bc bf didnt like friend  \n",
              "6                            sleep im thinking old friend want he married damn amp want scandalous  \n",
              "7                                                                                             hmmm  \n",
              "8                                                                               charlene love miss  \n",
              "9                                                                            im sorry least friday  \n",
              "10                                                                                cant fall asleep  \n",
              "11                                                                                 choked retainer  \n",
              "12                                                              ugh beat stupid song get next rude  \n",
              "13                         u watch hill london u realise tourture week week late watch itonlinelol  \n",
              "14                                                                                        got news  \n",
              "15                                                                          storm electricity gone  \n",
              "16                                                                                          agreed  \n",
              "17                                                                           sleepy even late fail  \n",
              "18                                                  lady gaga tweeted impressed video leaking know  \n",
              "19                              convinced always wanted signal give damn think lost another friend  \n",
              "20                                                   oh bad hope get better ive sleep issue lately  \n",
              "21  wondering im awake writing new song plotting evil secret plot muahahaha oh damn secret anymore  \n",
              "22                          topic map talk balisage markup conference program online via topicmaps  \n",
              "23                                                 ate something dont know keep telling thing food  \n",
              "24                       tired think im definitely going get ear infection going bed quotearlyquot  \n",
              "25          way home n deal w underage girl drinking gin da bus talking bout keggers damn feel old  \n",
              "26                                          im sorry people rude isaac get manner know better lewd  \n",
              "27                                                          damm server still need hit koxpers pas  \n",
              "28                                          fudge bsd whole paper tired ugh hate school time sleep  \n",
              "29                                                                      hate cancer hate hate hate  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82213f66-0cb8-471b-8d57-6e70e2f875da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "      <th>content_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
              "      <td>know listenin bad habit earlier started freakin part</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
              "      <td>layin n bed headache ughhhh waitin call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "      <td>want hang friend soon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
              "      <td>want trade someone houston ticket one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12</td>\n",
              "      <td>Re-pinging @ghostridah14: why didn't you go to prom? BC my bf didn't like my friends</td>\n",
              "      <td>repinging didnt go prom bc bf didnt like friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>I should be sleep, but im not! thinking about an old friend who I want. but he's married now. damn, &amp;amp; he wants me 2! scandalous!</td>\n",
              "      <td>sleep im thinking old friend want he married damn amp want scandalous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12</td>\n",
              "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
              "      <td>hmmm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>@charviray Charlene my love. I miss you</td>\n",
              "      <td>charlene love miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
              "      <td>im sorry least friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>8</td>\n",
              "      <td>cant fall asleep</td>\n",
              "      <td>cant fall asleep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>Choked on her retainers</td>\n",
              "      <td>choked retainer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>10</td>\n",
              "      <td>Ugh! I have to beat this stupid song to get to the next  rude!</td>\n",
              "      <td>ugh beat stupid song get next rude</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>10</td>\n",
              "      <td>@BrodyJenner if u watch the hills in london u will realise what tourture it is because were weeks and weeks late  i just watch itonlinelol</td>\n",
              "      <td>u watch hill london u realise tourture week week late watch itonlinelol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>11</td>\n",
              "      <td>Got the news</td>\n",
              "      <td>got news</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>10</td>\n",
              "      <td>The storm is here and the electricity is gone</td>\n",
              "      <td>storm electricity gone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7</td>\n",
              "      <td>@annarosekerr agreed</td>\n",
              "      <td>agreed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>10</td>\n",
              "      <td>So sleepy again and it's not even that late. I fail once again.</td>\n",
              "      <td>sleepy even late fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>12</td>\n",
              "      <td>@PerezHilton lady gaga tweeted about not being impressed by her video leaking just so you know</td>\n",
              "      <td>lady gaga tweeted impressed video leaking know</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>10</td>\n",
              "      <td>How are YOU convinced that I have always wanted you? What signals did I give off...damn I think I just lost another friend</td>\n",
              "      <td>convinced always wanted signal give damn think lost another friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>12</td>\n",
              "      <td>@raaaaaaek oh too bad! I hope it gets better. I've been having sleep issues lately too</td>\n",
              "      <td>oh bad hope get better ive sleep issue lately</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4</td>\n",
              "      <td>Wondering why I'm awake at 7am,writing a new song,plotting my evil secret plots muahahaha...oh damn it,not secret anymore</td>\n",
              "      <td>wondering im awake writing new song plotting evil secret plot muahahaha oh damn secret anymore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>8</td>\n",
              "      <td>No Topic Maps talks at the Balisage Markup Conference 2009   Program online at http://tr.im/mL6Z (via @bobdc) #topicmaps</td>\n",
              "      <td>topic map talk balisage markup conference program online via topicmaps</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>12</td>\n",
              "      <td>I ate Something I don't know what it is... Why do I keep Telling things about food</td>\n",
              "      <td>ate something dont know keep telling thing food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>10</td>\n",
              "      <td>so tired and i think i'm definitely going to get an ear infection.  going to bed &amp;quot;early&amp;quot; for once.</td>\n",
              "      <td>tired think im definitely going get ear infection going bed quotearlyquot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>12</td>\n",
              "      <td>On my way home n having 2 deal w underage girls drinking gin on da bus while talking bout keggers......damn i feel old</td>\n",
              "      <td>way home n deal w underage girl drinking gin da bus talking bout keggers damn feel old</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>10</td>\n",
              "      <td>@IsaacMascote  i'm sorry people are so rude to you, isaac, they should get some manners and know better than to be so lewd!</td>\n",
              "      <td>im sorry people rude isaac get manner know better lewd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>12</td>\n",
              "      <td>Damm servers still down  i need to hit 80 before all the koxpers pass me</td>\n",
              "      <td>damm server still need hit koxpers pas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>10</td>\n",
              "      <td>Fudge.... Just BS'd that whole paper.... So tired.... Ugh I hate school.....  time to sleep!!!!!!!!!!!</td>\n",
              "      <td>fudge bsd whole paper tired ugh hate school time sleep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>12</td>\n",
              "      <td>I HATE CANCER. I HATE IT I HATE IT I HATE IT.</td>\n",
              "      <td>hate cancer hate hate hate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82213f66-0cb8-471b-8d57-6e70e2f875da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82213f66-0cb8-471b-8d57-6e70e2f875da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82213f66-0cb8-471b-8d57-6e70e2f875da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "ktWErB1V-2td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "yzC277Ax7f51"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [len(t.split(' ')) for t in df['content_clean']]\n",
        "plt.hist(lengths, bins=len(set(lengths)))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vYZ9B2AiLrUs",
        "outputId": "dcce729d-2ac7-46a6-d7bb-690f31ec4430"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtO0lEQVR4nO3df3AUZZ7H8U8IyRB+zGDAZJIjYBQFAglqXMOcyuISM0D09MAqURaiBijYxJNEAXPHIrBbho3nCq4Kt+Xt4lWB/LgSPckJxmDCKQHc7KaAKCmhsIIFk7i6mYEIAZK+P6z0OoJKwoTJE9+vqi4z3d955tttl/PxmZ6eCMuyLAEAABikV7gbAAAA6CgCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOL3D3UBXaWtr0/HjxzVgwABFRESEux0AAHAJLMvSyZMnlZiYqF69vnuepccGmOPHjyspKSncbQAAgE44duyYhgwZ8p3bLyvArFy5UkVFRXr88ce1atUqSdKZM2f0xBNPaOPGjWppaZHX69XLL7+s+Ph4+3n19fWaP3++3nvvPfXv3185OTkqLi5W795/b6eiokKFhYWqra1VUlKSlixZoocffviSexswYICkrw+A0+m8nN0EAABXSCAQUFJSkv0+/l06HWA+/PBD/cd//IfS0tKC1hcUFKi0tFRbtmyRy+VSfn6+pk6dqg8++ECS1NraquzsbLndbu3evVsnTpzQrFmzFBUVpWeeeUaSdPToUWVnZ2vevHlav369ysvLNXv2bCUkJMjr9V5Sf+0fGzmdTgIMAACG+cHLP6xOOHnypHX99ddbZWVl1k9/+lPr8ccftyzLspqamqyoqChry5Ytdu3HH39sSbKqqqosy7Ks//3f/7V69epl+Xw+u2bNmjWW0+m0WlpaLMuyrEWLFlmjR48Oes0HHnjA8nq9l9yj3++3JFl+v78zuwgAAMLgUt+/O/UtpLy8PGVnZyszMzNofXV1tc6dOxe0fuTIkRo6dKiqqqokSVVVVUpNTQ36SMnr9SoQCKi2ttau+fbYXq/XHuNiWlpaFAgEghYAANAzdfgjpI0bN+rPf/6zPvzwwwu2+Xw+RUdHa+DAgUHr4+Pj5fP57Jpvhpf27e3bvq8mEAjo9OnTiomJueC1i4uLtXz58o7uDgAAMFCHZmCOHTumxx9/XOvXr1efPn26qqdOKSoqkt/vt5djx46FuyUAANBFOhRgqqur1djYqJtvvlm9e/dW7969VVlZqRdeeEG9e/dWfHy8zp49q6ampqDnNTQ0yO12S5LcbrcaGhou2N6+7ftqnE7nRWdfJMnhcNgX7HLhLgAAPVuHAszEiRN14MAB1dTU2Mstt9yiGTNm2H9HRUWpvLzcfk5dXZ3q6+vl8XgkSR6PRwcOHFBjY6NdU1ZWJqfTqZSUFLvmm2O017SPAQAAftw6dA3MgAEDNGbMmKB1/fr106BBg+z1ubm5KiwsVGxsrJxOpx577DF5PB6NGzdOkpSVlaWUlBTNnDlTJSUl8vl8WrJkifLy8uRwOCRJ8+bN04svvqhFixbp0Ucf1c6dO7V582aVlpaGYp8BAIDhQn4n3ueff169evXStGnTgm5k1y4yMlLbtm3T/Pnz5fF41K9fP+Xk5GjFihV2TXJyskpLS1VQUKDVq1dryJAheuWVVy75HjAAAKBni7Asywp3E10hEAjI5XLJ7/dzPQwAAIa41Pdvfo0aAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxQv41apjtmqdCc6+dT1dmh2QcAAAuhhkYAABgHGZg0CWYyQEAdCVmYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHH4LCd0av6kEALgYZmAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHG4E28PEKq71QIAYApmYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGKdDAWbNmjVKS0uT0+mU0+mUx+PR22+/bW+fMGGCIiIigpZ58+YFjVFfX6/s7Gz17dtXcXFxWrhwoc6fPx9UU1FRoZtvvlkOh0PDhw/XunXrOr+HAACgx+nQ16iHDBmilStX6vrrr5dlWXr11Vd177336i9/+YtGjx4tSZozZ45WrFhhP6dv3772362trcrOzpbb7dbu3bt14sQJzZo1S1FRUXrmmWckSUePHlV2drbmzZun9evXq7y8XLNnz1ZCQoK8Xm8o9hkAABguwrIs63IGiI2N1bPPPqvc3FxNmDBBN954o1atWnXR2rffflt33323jh8/rvj4eEnS2rVrtXjxYn3++eeKjo7W4sWLVVpaqoMHD9rPmz59upqamrR9+/ZL7isQCMjlcsnv98vpdF7OLnZ73Afmh326MjvcLQAALsGlvn93+hqY1tZWbdy4Uc3NzfJ4PPb69evXa/DgwRozZoyKior01Vdf2duqqqqUmppqhxdJ8nq9CgQCqq2ttWsyMzODXsvr9aqqqup7+2lpaVEgEAhaAABAz9ThO/EeOHBAHo9HZ86cUf/+/bV161alpKRIkh566CENGzZMiYmJ2r9/vxYvXqy6ujq9/vrrkiSfzxcUXiTZj30+3/fWBAIBnT59WjExMRftq7i4WMuXL+/o7gAAAAN1OMCMGDFCNTU18vv9+u///m/l5OSosrJSKSkpmjt3rl2XmpqqhIQETZw4UUeOHNF1110X0sa/raioSIWFhfbjQCCgpKSkLn1NAAAQHh3+CCk6OlrDhw9Xenq6iouLNXbsWK1evfqitRkZGZKkw4cPS5LcbrcaGhqCatofu93u761xOp3fOfsiSQ6Hw/52VPsCAAB6psu+D0xbW5taWlouuq2mpkaSlJCQIEnyeDw6cOCAGhsb7ZqysjI5nU77YyiPx6Py8vKgccrKyoKuswEAAD9uHfoIqaioSJMnT9bQoUN18uRJbdiwQRUVFdqxY4eOHDmiDRs2aMqUKRo0aJD279+vgoICjR8/XmlpaZKkrKwspaSkaObMmSopKZHP59OSJUuUl5cnh8MhSZo3b55efPFFLVq0SI8++qh27typzZs3q7SUb9oAAICvdSjANDY2atasWTpx4oRcLpfS0tK0Y8cO3XXXXTp27JjeffddrVq1Ss3NzUpKStK0adO0ZMkS+/mRkZHatm2b5s+fL4/Ho379+iknJyfovjHJyckqLS1VQUGBVq9erSFDhuiVV17hHjAAAMB22feB6a64Dwy+ifvAAIAZuvw+MAAAAOFCgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgd/ikBwESh+qYW32YCgO6BGRgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIzToQCzZs0apaWlyel0yul0yuPx6O2337a3nzlzRnl5eRo0aJD69++vadOmqaGhIWiM+vp6ZWdnq2/fvoqLi9PChQt1/vz5oJqKigrdfPPNcjgcGj58uNatW9f5PQQAAD1O744UDxkyRCtXrtT1118vy7L06quv6t5779Vf/vIXjR49WgUFBSotLdWWLVvkcrmUn5+vqVOn6oMPPpAktba2Kjs7W263W7t379aJEyc0a9YsRUVF6ZlnnpEkHT16VNnZ2Zo3b57Wr1+v8vJyzZ49WwkJCfJ6vaE/AkAHXPNUaUjG+XRldkjGAYAfqwjLsqzLGSA2NlbPPvus7r//fl199dXasGGD7r//fknSoUOHNGrUKFVVVWncuHF6++23dffdd+v48eOKj4+XJK1du1aLFy/W559/rujoaC1evFilpaU6ePCg/RrTp09XU1OTtm/ffsl9BQIBuVwu+f1+OZ3Oy9nFbi9Ub6q4cggwAHBxl/r+3elrYFpbW7Vx40Y1NzfL4/Gourpa586dU2Zmpl0zcuRIDR06VFVVVZKkqqoqpaam2uFFkrxerwKBgGpra+2ab47RXtM+xndpaWlRIBAIWgAAQM/U4QBz4MAB9e/fXw6HQ/PmzdPWrVuVkpIin8+n6OhoDRw4MKg+Pj5ePp9PkuTz+YLCS/v29m3fVxMIBHT69Onv7Ku4uFgul8tekpKSOrprAADAEB0OMCNGjFBNTY327t2r+fPnKycnRx999FFX9NYhRUVF8vv99nLs2LFwtwQAALpIhy7ilaTo6GgNHz5ckpSenq4PP/xQq1ev1gMPPKCzZ8+qqakpaBamoaFBbrdbkuR2u7Vv376g8dq/pfTNmm9/c6mhoUFOp1MxMTHf2ZfD4ZDD4ejo7gAAAANd9n1g2tra1NLSovT0dEVFRam8vNzeVldXp/r6enk8HkmSx+PRgQMH1NjYaNeUlZXJ6XQqJSXFrvnmGO017WMAAAB0aAamqKhIkydP1tChQ3Xy5Elt2LBBFRUV2rFjh1wul3Jzc1VYWKjY2Fg5nU499thj8ng8GjdunCQpKytLKSkpmjlzpkpKSuTz+bRkyRLl5eXZsyfz5s3Tiy++qEWLFunRRx/Vzp07tXnzZpWW8k0bAADwtQ4FmMbGRs2aNUsnTpyQy+VSWlqaduzYobvuukuS9Pzzz6tXr16aNm2aWlpa5PV69fLLL9vPj4yM1LZt2zR//nx5PB7169dPOTk5WrFihV2TnJys0tJSFRQUaPXq1RoyZIheeeUV7gEDAABsl30fmO6K+8CgO+M+MABwcV1+HxgAAIBwIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABinw7+FhNDh/i0AAHQOMzAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDjciRcIg1DdhfnTldkhGQcATMMMDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADBOhwJMcXGxfvKTn2jAgAGKi4vTfffdp7q6uqCaCRMmKCIiImiZN29eUE19fb2ys7PVt29fxcXFaeHChTp//nxQTUVFhW6++WY5HA4NHz5c69at69weAgCAHqdDAaayslJ5eXnas2ePysrKdO7cOWVlZam5uTmobs6cOTpx4oS9lJSU2NtaW1uVnZ2ts2fPavfu3Xr11Ve1bt06LV261K45evSosrOzdeedd6qmpkYLFizQ7NmztWPHjsvcXQAA0BP07kjx9u3bgx6vW7dOcXFxqq6u1vjx4+31ffv2ldvtvugY77zzjj766CO9++67io+P14033qhf/epXWrx4sZYtW6bo6GitXbtWycnJeu655yRJo0aN0vvvv6/nn39eXq+3o/sIAAB6mMu6Bsbv90uSYmNjg9avX79egwcP1pgxY1RUVKSvvvrK3lZVVaXU1FTFx8fb67xerwKBgGpra+2azMzMoDG9Xq+qqqq+s5eWlhYFAoGgBQAA9EwdmoH5pra2Ni1YsEC33XabxowZY69/6KGHNGzYMCUmJmr//v1avHix6urq9Prrr0uSfD5fUHiRZD/2+XzfWxMIBHT69GnFxMRc0E9xcbGWL1/e2d0BAAAG6XSAycvL08GDB/X+++8HrZ87d679d2pqqhISEjRx4kQdOXJE1113Xec7/QFFRUUqLCy0HwcCASUlJXXZ6wEAgPDp1EdI+fn52rZtm9577z0NGTLke2szMjIkSYcPH5Ykud1uNTQ0BNW0P26/bua7apxO50VnXyTJ4XDI6XQGLQAAoGfqUICxLEv5+fnaunWrdu7cqeTk5B98Tk1NjSQpISFBkuTxeHTgwAE1NjbaNWVlZXI6nUpJSbFrysvLg8YpKyuTx+PpSLsAAKCHirAsy7rU4l/84hfasGGD3nzzTY0YMcJe73K5FBMToyNHjmjDhg2aMmWKBg0apP3796ugoEBDhgxRZWWlpK+/Rn3jjTcqMTFRJSUl8vl8mjlzpmbPnq1nnnlG0tdfox4zZozy8vL06KOPaufOnfqXf/kXlZaWXvK3kAKBgFwul/x+f7edjbnmqdJwtwBIkj5dmR3uFgBA0qW/f3doBmbNmjXy+/2aMGGCEhIS7GXTpk2SpOjoaL377rvKysrSyJEj9cQTT2jatGl666237DEiIyO1bds2RUZGyuPx6Oc//7lmzZqlFStW2DXJyckqLS1VWVmZxo4dq+eee06vvPIKX6EGAACSOjgDYxJmYIBLxwwMgO6iS2ZgAAAAugMCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOJ3+NWoAPUeobqrIDfEAXCnMwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOP07khxcXGxXn/9dR06dEgxMTH6x3/8R/3mN7/RiBEj7JozZ87oiSee0MaNG9XS0iKv16uXX35Z8fHxdk19fb3mz5+v9957T/3791dOTo6Ki4vVu/ff26moqFBhYaFqa2uVlJSkJUuW6OGHH778PQbQZa55qjQk43y6Mjsk4wDouTo0A1NZWam8vDzt2bNHZWVlOnfunLKystTc3GzXFBQU6K233tKWLVtUWVmp48ePa+rUqfb21tZWZWdn6+zZs9q9e7deffVVrVu3TkuXLrVrjh49quzsbN15552qqanRggULNHv2bO3YsSMEuwwAAEwXYVmW1dknf/7554qLi1NlZaXGjx8vv9+vq6++Whs2bND9998vSTp06JBGjRqlqqoqjRs3Tm+//bbuvvtuHT9+3J6VWbt2rRYvXqzPP/9c0dHRWrx4sUpLS3Xw4EH7taZPn66mpiZt3779knoLBAJyuVzy+/1yOp2d3cUuFar/WwV6GmZggB+vS33/vqxrYPx+vyQpNjZWklRdXa1z584pMzPTrhk5cqSGDh2qqqoqSVJVVZVSU1ODPlLyer0KBAKqra21a745RntN+xgX09LSokAgELQAAICeqdMBpq2tTQsWLNBtt92mMWPGSJJ8Pp+io6M1cODAoNr4+Hj5fD675pvhpX17+7bvqwkEAjp9+vRF+ykuLpbL5bKXpKSkzu4aAADo5jodYPLy8nTw4EFt3LgxlP10WlFRkfx+v70cO3Ys3C0BAIAu0qFvIbXLz8/Xtm3btGvXLg0ZMsRe73a7dfbsWTU1NQXNwjQ0NMjtdts1+/btCxqvoaHB3tb+z/Z136xxOp2KiYm5aE8Oh0MOh6MzuwMAAAzToRkYy7KUn5+vrVu3aufOnUpOTg7anp6erqioKJWXl9vr6urqVF9fL4/HI0nyeDw6cOCAGhsb7ZqysjI5nU6lpKTYNd8co72mfQwAAPDj1qEZmLy8PG3YsEFvvvmmBgwYYF+z4nK5FBMTI5fLpdzcXBUWFio2NlZOp1OPPfaYPB6Pxo0bJ0nKyspSSkqKZs6cqZKSEvl8Pi1ZskR5eXn2DMq8efP04osvatGiRXr00Ue1c+dObd68WaWlfGsHAAB0cAZmzZo18vv9mjBhghISEuxl06ZNds3zzz+vu+++W9OmTdP48ePldrv1+uuv29sjIyO1bds2RUZGyuPx6Oc//7lmzZqlFStW2DXJyckqLS1VWVmZxo4dq+eee06vvPKKvF5vCHYZAACY7rLuA9OdcR8YwFzcBwb48boi94EBAAAIBwIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACM0zvcDQDAt13zVGlIxvl0ZXZIxgHQ/TADAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgnA4HmF27dumee+5RYmKiIiIi9MYbbwRtf/jhhxURERG0TJo0Kajmyy+/1IwZM+R0OjVw4EDl5ubq1KlTQTX79+/XHXfcoT59+igpKUklJSUd3zsAANAjdTjANDc3a+zYsXrppZe+s2bSpEk6ceKEvbz22mtB22fMmKHa2lqVlZVp27Zt2rVrl+bOnWtvDwQCysrK0rBhw1RdXa1nn31Wy5Yt0+9///uOtgsAAHqgDt/IbvLkyZo8efL31jgcDrnd7otu+/jjj7V9+3Z9+OGHuuWWWyRJv/vd7zRlyhT9+7//uxITE7V+/XqdPXtWf/jDHxQdHa3Ro0erpqZGv/3tb4OCDgAA+HHqkmtgKioqFBcXpxEjRmj+/Pn64osv7G1VVVUaOHCgHV4kKTMzU7169dLevXvtmvHjxys6Otqu8Xq9qqur09/+9reLvmZLS4sCgUDQAgAAeqaQB5hJkybpv/7rv1ReXq7f/OY3qqys1OTJk9Xa2ipJ8vl8iouLC3pO7969FRsbK5/PZ9fEx8cH1bQ/bq/5tuLiYrlcLntJSkoK9a4BAIBuIuS/hTR9+nT779TUVKWlpem6665TRUWFJk6cGOqXsxUVFamwsNB+HAgECDEAAPRQXf5jjtdee60GDx6sw4cPa+LEiXK73WpsbAyqOX/+vL788kv7uhm3262GhoagmvbH33VtjcPhkMPh6II9uFCofmgOAAB0TpffB+azzz7TF198oYSEBEmSx+NRU1OTqqur7ZqdO3eqra1NGRkZds2uXbt07tw5u6asrEwjRozQVVdd1dUtAwCAbq7DAebUqVOqqalRTU2NJOno0aOqqalRfX29Tp06pYULF2rPnj369NNPVV5ernvvvVfDhw+X1+uVJI0aNUqTJk3SnDlztG/fPn3wwQfKz8/X9OnTlZiYKEl66KGHFB0drdzcXNXW1mrTpk1avXp10EdEAADgx6vDAeZPf/qTbrrpJt10002SpMLCQt10001aunSpIiMjtX//fv3TP/2TbrjhBuXm5io9PV3/93//F/Txzvr16zVy5EhNnDhRU6ZM0e233x50jxeXy6V33nlHR48eVXp6up544gktXbqUr1ADAABJUoRlWVa4m+gKgUBALpdLfr9fTqczpGNzDQxghk9XZoe7BQAddKnv3/wWEgAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGCc3uFuAAC6yjVPlYZknE9XZodkHAChwwwMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAME6HA8yuXbt0zz33KDExUREREXrjjTeCtluWpaVLlyohIUExMTHKzMzUJ598ElTz5ZdfasaMGXI6nRo4cKByc3N16tSpoJr9+/frjjvuUJ8+fZSUlKSSkpKO7x0AAOiROhxgmpubNXbsWL300ksX3V5SUqIXXnhBa9eu1d69e9WvXz95vV6dOXPGrpkxY4Zqa2tVVlambdu2adeuXZo7d669PRAIKCsrS8OGDVN1dbWeffZZLVu2TL///e87sYsAAKCnibAsy+r0kyMitHXrVt13332Svp59SUxM1BNPPKEnn3xSkuT3+xUfH69169Zp+vTp+vjjj5WSkqIPP/xQt9xyiyRp+/btmjJlij777DMlJiZqzZo1+rd/+zf5fD5FR0dLkp566im98cYbOnTo0CX1FggE5HK55Pf75XQ6O7uLF3XNU6UhHQ9A9/bpyuxwtwD8aFzq+3dIr4E5evSofD6fMjMz7XUul0sZGRmqqqqSJFVVVWngwIF2eJGkzMxM9erVS3v37rVrxo8fb4cXSfJ6vaqrq9Pf/va3i752S0uLAoFA0AIAAHqmkAYYn88nSYqPjw9aHx8fb2/z+XyKi4sL2t67d2/FxsYG1VxsjG++xrcVFxfL5XLZS1JS0uXvEAAA6JZ6zLeQioqK5Pf77eXYsWPhbgkAAHSRkAYYt9stSWpoaAha39DQYG9zu91qbGwM2n7+/Hl9+eWXQTUXG+Obr/FtDodDTqczaAEAAD1TSANMcnKy3G63ysvL7XWBQEB79+6Vx+ORJHk8HjU1Nam6utqu2blzp9ra2pSRkWHX7Nq1S+fOnbNrysrKNGLECF111VWhbBkAABiowwHm1KlTqqmpUU1NjaSvL9ytqalRfX29IiIitGDBAv3617/W//zP/+jAgQOaNWuWEhMT7W8qjRo1SpMmTdKcOXO0b98+ffDBB8rPz9f06dOVmJgoSXrooYcUHR2t3Nxc1dbWatOmTVq9erUKCwtDtuMAAMBcvTv6hD/96U+688477cftoSInJ0fr1q3TokWL1NzcrLlz56qpqUm33367tm/frj59+tjPWb9+vfLz8zVx4kT16tVL06ZN0wsvvGBvd7lceuedd5SXl6f09HQNHjxYS5cuDbpXDAAA+PG6rPvAdGfcBwZAqHAfGODKCct9YAAAAK4EAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGKfDP+YIAD82ofr9M35TCQgdZmAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGCXmAWbZsmSIiIoKWkSNH2tvPnDmjvLw8DRo0SP3799e0adPU0NAQNEZ9fb2ys7PVt29fxcXFaeHChTp//nyoWwUAAIbq3RWDjh49Wu++++7fX6T331+moKBApaWl2rJli1wul/Lz8zV16lR98MEHkqTW1lZlZ2fL7XZr9+7dOnHihGbNmqWoqCg988wzXdEuAAAwTJcEmN69e8vtdl+w3u/36z//8z+1YcMG/exnP5Mk/fGPf9SoUaO0Z88ejRs3Tu+8844++ugjvfvuu4qPj9eNN96oX/3qV1q8eLGWLVum6OjormgZAAAYpEuugfnkk0+UmJioa6+9VjNmzFB9fb0kqbq6WufOnVNmZqZdO3LkSA0dOlRVVVWSpKqqKqWmpio+Pt6u8Xq9CgQCqq2t/c7XbGlpUSAQCFoAAEDPFPIAk5GRoXXr1mn79u1as2aNjh49qjvuuEMnT56Uz+dTdHS0Bg4cGPSc+Ph4+Xw+SZLP5wsKL+3b27d9l+LiYrlcLntJSkoK7Y4BAIBuI+QfIU2ePNn+Oy0tTRkZGRo2bJg2b96smJiYUL+craioSIWFhfbjQCBAiAEAoIfqkmtgvmngwIG64YYbdPjwYd111106e/asmpqagmZhGhoa7Gtm3G639u3bFzRG+7eULnZdTTuHwyGHwxH6HQCAELnmqdKQjPPpyuyQjAOYrMvvA3Pq1CkdOXJECQkJSk9PV1RUlMrLy+3tdXV1qq+vl8fjkSR5PB4dOHBAjY2Ndk1ZWZmcTqdSUlK6ul0AAGCAkM/APPnkk7rnnns0bNgwHT9+XE8//bQiIyP14IMPyuVyKTc3V4WFhYqNjZXT6dRjjz0mj8ejcePGSZKysrKUkpKimTNnqqSkRD6fT0uWLFFeXh4zLAAAQFIXBJjPPvtMDz74oL744gtdffXVuv3227Vnzx5dffXVkqTnn39evXr10rRp09TS0iKv16uXX37Zfn5kZKS2bdum+fPny+PxqF+/fsrJydGKFStC3SoAADBUhGVZVrib6AqBQEAul0t+v19OpzOkY4fqc2wA6AyugUFPdqnv3/wWEgAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4vcPdAACgY655qjQk43y6Mjsk4wDhwAwMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIzDbyEBwI8Uv6kEkzEDAwAAjEOAAQAAxiHAAAAA4xBgAACAcbiIFwBwWbgYGOHADAwAADBOtw4wL730kq655hr16dNHGRkZ2rdvX7hbAgAA3UC3/Qhp06ZNKiws1Nq1a5WRkaFVq1bJ6/Wqrq5OcXFx4W4PABBifBSFjui2MzC//e1vNWfOHD3yyCNKSUnR2rVr1bdvX/3hD38Id2sAACDMuuUMzNmzZ1VdXa2ioiJ7Xa9evZSZmamqqqqLPqelpUUtLS32Y7/fL0kKBAIh76+t5auQjwkACI2u+O8+rpz2f3+WZX1vXbcMMH/961/V2tqq+Pj4oPXx8fE6dOjQRZ9TXFys5cuXX7A+KSmpS3oEAHRPrlXh7gChcPLkSblcru/c3i0DTGcUFRWpsLDQftzW1qYvv/xSgwYNUkREhAKBgJKSknTs2DE5nc4wdtrzcayvDI7zlcFxvjI4zleGCcfZsiydPHlSiYmJ31vXLQPM4MGDFRkZqYaGhqD1DQ0NcrvdF32Ow+GQw+EIWjdw4MAL6pxOZ7f9l9bTcKyvDI7zlcFxvjI4zldGdz/O3zfz0q5bXsQbHR2t9PR0lZeX2+va2tpUXl4uj8cTxs4AAEB30C1nYCSpsLBQOTk5uuWWW3Trrbdq1apVam5u1iOPPBLu1gAAQJh12wDzwAMP6PPPP9fSpUvl8/l04403avv27Rdc2HupHA6Hnn766Qs+ZkLocayvDI7zlcFxvjI4zldGTzrOEdYPfU8JAACgm+mW18AAAAB8HwIMAAAwDgEGAAAYhwADAACM86MJMC+99JKuueYa9enTRxkZGdq3b1+4W+pRli1bpoiIiKBl5MiR4W7LeLt27dI999yjxMRERURE6I033gjablmWli5dqoSEBMXExCgzM1OffPJJeJo13A8d64cffviCc3zSpEnhadZQxcXF+slPfqIBAwYoLi5O9913n+rq6oJqzpw5o7y8PA0aNEj9+/fXtGnTLripKX7YpRzrCRMmXHBOz5s3L0wdd9yPIsBs2rRJhYWFevrpp/XnP/9ZY8eOldfrVWNjY7hb61FGjx6tEydO2Mv7778f7paM19zcrLFjx+qll1666PaSkhK98MILWrt2rfbu3at+/frJ6/XqzJkzV7hT8/3QsZakSZMmBZ3jr7322hXs0HyVlZXKy8vTnj17VFZWpnPnzikrK0vNzc12TUFBgd566y1t2bJFlZWVOn78uKZOnRrGrs10KcdakubMmRN0TpeUlISp406wfgRuvfVWKy8vz37c2tpqJSYmWsXFxWHsqmd5+umnrbFjx4a7jR5NkrV161b7cVtbm+V2u61nn33WXtfU1GQ5HA7rtddeC0OHPce3j7VlWVZOTo517733hqWfnqqxsdGSZFVWVlqW9fX5GxUVZW3ZssWu+fjjjy1JVlVVVbja7BG+fawty7J++tOfWo8//nj4mrpMPX4G5uzZs6qurlZmZqa9rlevXsrMzFRVVVUYO+t5PvnkEyUmJuraa6/VjBkzVF9fH+6WerSjR4/K5/MFndsul0sZGRmc212koqJCcXFxGjFihObPn68vvvgi3C0Zze/3S5JiY2MlSdXV1Tp37lzQOT1y5EgNHTqUc/oyfftYt1u/fr0GDx6sMWPGqKioSF999VU42uuUbnsn3lD561//qtbW1gvu4BsfH69Dhw6FqaueJyMjQ+vWrdOIESN04sQJLV++XHfccYcOHjyoAQMGhLu9Hsnn80nSRc/t9m0InUmTJmnq1KlKTk7WkSNH9K//+q+aPHmyqqqqFBkZGe72jNPW1qYFCxbotttu05gxYyR9fU5HR0df8EO8nNOX52LHWpIeeughDRs2TImJidq/f78WL16suro6vf7662Hs9tL1+ACDK2Py5Mn232lpacrIyNCwYcO0efNm5ebmhrEzIDSmT59u/52amqq0tDRdd911qqio0MSJE8PYmZny8vJ08OBBrpW7Ar7rWM+dO9f+OzU1VQkJCZo4caKOHDmi66677kq32WE9/iOkwYMHKzIy8oKr2BsaGuR2u8PUVc83cOBA3XDDDTp8+HC4W+mx2s9fzu3wuPbaazV48GDO8U7Iz8/Xtm3b9N5772nIkCH2erfbrbNnz6qpqSmonnO6877rWF9MRkaGJBlzTvf4ABMdHa309HSVl5fb69ra2lReXi6PxxPGznq2U6dO6ciRI0pISAh3Kz1WcnKy3G530LkdCAS0d+9ezu0r4LPPPtMXX3zBOd4BlmUpPz9fW7du1c6dO5WcnBy0PT09XVFRUUHndF1dnerr6zmnO+iHjvXF1NTUSJIx5/SP4iOkwsJC5eTk6JZbbtGtt96qVatWqbm5WY888ki4W+sxnnzySd1zzz0aNmyYjh8/rqefflqRkZF68MEHw92a0U6dOhX0f0NHjx5VTU2NYmNjNXToUC1YsEC//vWvdf311ys5OVm//OUvlZiYqPvuuy98TRvq+451bGysli9frmnTpsntduvIkSNatGiRhg8fLq/XG8auzZKXl6cNGzbozTff1IABA+zrWlwul2JiYuRyuZSbm6vCwkLFxsbK6XTqsccek8fj0bhx48LcvVl+6FgfOXJEGzZs0JQpUzRo0CDt379fBQUFGj9+vNLS0sLc/SUK99egrpTf/e531tChQ63o6Gjr1ltvtfbs2RPulnqUBx54wEpISLCio6Otf/iHf7AeeOAB6/Dhw+Fuy3jvvfeeJemCJScnx7Ksr79K/ctf/tKKj4+3HA6HNXHiRKuuri68TRvq+471V199ZWVlZVlXX321FRUVZQ0bNsyaM2eO5fP5wt22US52fCVZf/zjH+2a06dPW7/4xS+sq666yurbt6/1z//8z9aJEyfC17ShfuhY19fXW+PHj7diY2Mth8NhDR8+3Fq4cKHl9/vD23gHRFiWZV3JwAQAAHC5evw1MAAAoOchwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOP8PHNypTOPXYlkAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The appropriate max words per sentence seems to be 20"
      ],
      "metadata": {
        "id": "2zvt6gkAmsV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 20\n",
        "vocab_size = 30000  # total number of word count was found to be just above 30000"
      ],
      "metadata": {
        "id": "ba_tXzPxLpWT"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")   # initialize tokenizer with an out of vocabulary token\n",
        "tokenizer.fit_on_texts(df['content_clean'])                      # fit on the cleaned tweets data\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)"
      ],
      "metadata": {
        "id": "d_fD7LqHLp8f"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_seqeuences(tokenizer, tweets):\n",
        "  sequences = tokenizer.texts_to_sequences(tweets)                  # converting each sentence to tokenized numeric sequences\n",
        "  padded = pad_sequences(sequences, truncating=\"post\", padding=\"post\", maxlen=maxlen) # post padding- fill with zeroes to the end & post truncate would truncate larger than maxlen at the end\n",
        "  return padded"
      ],
      "metadata": {
        "id": "EChcF8UrMVLw"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tweets = get_seqeuences(tokenizer, df['content_clean'])"
      ],
      "metadata": {
        "id": "IaCJM2urMxAH"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "h_861a4xNVrE"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(padded_tweets, df['sentiment'], test_size=0.2, random_state=134) #splitting train and test data with 80:20 ratio"
      ],
      "metadata": {
        "id": "aJhb6dE9NaGJ"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "B-eTrdw8NwQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, GlobalAveragePooling1D, Flatten, Dropout\n",
        "from tensorflow.keras.regularizers import l2, l1_l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "NPAzV6UTN0bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bidirectional LSTM Architecture with softmax activated output layer for multiclass classification"
      ],
      "metadata": {
        "id": "D_bohACjpF_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()  # model with layers added sequentially\n",
        "model.add(Embedding(vocab_size, 16, input_length = maxlen, embeddings_regularizer=l2(0.01)))\n",
        "model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(32, activation = \"relu\", kernel_regularizer=l2(0.02)))\n",
        "model.add(Dropout(0.5))      # dropout layer to prevent overfitting\n",
        "model.add(Dense(emotion_count, activation = \"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duOWDLS5vLNV",
        "outputId": "9643aed9-a52e-4382-884f-e16e8abadd73"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 20, 16)            481712    \n",
            "                                                                 \n",
            " bidirectional_22 (Bidirecti  (None, 20, 40)           5920      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_23 (Bidirecti  (None, 40)               9760      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 32)                1312      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 499,133\n",
            "Trainable params: 499,133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling with sparse categorical crossentropy because outputs are label encoded, evaluation policy is accuracy and optimizer is Adam.\n",
        "Also added an early stopping callback to prevent overfitting and also return best results"
      ],
      "metadata": {
        "id": "NWH_EwePs2Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50, callbacks=[EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbLEFG9FO-is",
        "outputId": "4ed26726-e602-4fc1-c96f-e16cf90aa342"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1000/1000 [==============================] - 20s 14ms/step - loss: 2.3513 - accuracy: 0.2153 - val_loss: 2.1464 - val_accuracy: 0.2520\n",
            "Epoch 2/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.1795 - accuracy: 0.2373 - val_loss: 2.1569 - val_accuracy: 0.2414\n",
            "Epoch 3/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.1788 - accuracy: 0.2424 - val_loss: 2.1249 - val_accuracy: 0.2491\n",
            "Epoch 4/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.1443 - accuracy: 0.2530 - val_loss: 2.0906 - val_accuracy: 0.2570\n",
            "Epoch 5/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.1224 - accuracy: 0.2674 - val_loss: 2.0755 - val_accuracy: 0.3091\n",
            "Epoch 6/50\n",
            "1000/1000 [==============================] - 11s 11ms/step - loss: 2.1063 - accuracy: 0.2927 - val_loss: 2.0622 - val_accuracy: 0.3027\n",
            "Epoch 7/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0914 - accuracy: 0.2984 - val_loss: 2.0426 - val_accuracy: 0.3250\n",
            "Epoch 8/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0716 - accuracy: 0.3051 - val_loss: 2.0313 - val_accuracy: 0.3298\n",
            "Epoch 9/50\n",
            "1000/1000 [==============================] - 11s 11ms/step - loss: 2.0555 - accuracy: 0.3062 - val_loss: 2.0305 - val_accuracy: 0.3178\n",
            "Epoch 10/50\n",
            "1000/1000 [==============================] - 11s 11ms/step - loss: 2.0482 - accuracy: 0.3108 - val_loss: 2.0275 - val_accuracy: 0.3226\n",
            "Epoch 11/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0420 - accuracy: 0.3168 - val_loss: 2.0249 - val_accuracy: 0.3232\n",
            "Epoch 12/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0420 - accuracy: 0.3162 - val_loss: 2.0181 - val_accuracy: 0.3255\n",
            "Epoch 13/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0377 - accuracy: 0.3206 - val_loss: 2.0226 - val_accuracy: 0.3288\n",
            "Epoch 14/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0348 - accuracy: 0.3213 - val_loss: 2.0225 - val_accuracy: 0.3325\n",
            "Epoch 15/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0316 - accuracy: 0.3218 - val_loss: 2.0266 - val_accuracy: 0.3288\n",
            "Epoch 16/50\n",
            "1000/1000 [==============================] - 16s 16ms/step - loss: 2.0359 - accuracy: 0.3204 - val_loss: 2.0304 - val_accuracy: 0.3231\n",
            "Epoch 17/50\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 2.0316 - accuracy: 0.3241 - val_loss: 2.0268 - val_accuracy: 0.3282\n",
            "Epoch 18/50\n",
            "1000/1000 [==============================] - 17s 17ms/step - loss: 2.0360 - accuracy: 0.3208 - val_loss: 2.0250 - val_accuracy: 0.3261\n",
            "Epoch 19/50\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 2.0361 - accuracy: 0.3208 - val_loss: 2.0306 - val_accuracy: 0.3298\n",
            "Epoch 20/50\n",
            "1000/1000 [==============================] - 11s 11ms/step - loss: 2.0370 - accuracy: 0.3246 - val_loss: 2.0335 - val_accuracy: 0.3322\n",
            "Epoch 21/50\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 2.0395 - accuracy: 0.3245 - val_loss: 2.0287 - val_accuracy: 0.3316\n",
            "Epoch 22/50\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 2.0342 - accuracy: 0.3279 - val_loss: 2.0253 - val_accuracy: 0.3347\n",
            "Epoch 23/50\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 2.0348 - accuracy: 0.3287 - val_loss: 2.0355 - val_accuracy: 0.3250\n",
            "Epoch 24/50\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 2.0392 - accuracy: 0.3262 - val_loss: 2.0265 - val_accuracy: 0.3352\n",
            "Epoch 25/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0372 - accuracy: 0.3290 - val_loss: 2.0296 - val_accuracy: 0.3340\n",
            "Epoch 26/50\n",
            "1000/1000 [==============================] - 11s 11ms/step - loss: 2.0348 - accuracy: 0.3288 - val_loss: 2.0244 - val_accuracy: 0.3392\n",
            "Epoch 27/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0346 - accuracy: 0.3296 - val_loss: 2.0314 - val_accuracy: 0.3250\n",
            "Epoch 28/50\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 2.0312 - accuracy: 0.3331 - val_loss: 2.0304 - val_accuracy: 0.3324\n",
            "Epoch 29/50\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 2.0320 - accuracy: 0.3312 - val_loss: 2.0340 - val_accuracy: 0.3322\n",
            "Epoch 30/50\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 2.0330 - accuracy: 0.3293 - val_loss: 2.0350 - val_accuracy: 0.3324\n",
            "Epoch 31/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0299 - accuracy: 0.3359 - val_loss: 2.0319 - val_accuracy: 0.3339\n",
            "Epoch 32/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0308 - accuracy: 0.3345 - val_loss: 2.0280 - val_accuracy: 0.3304\n",
            "Epoch 33/50\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 2.0283 - accuracy: 0.3394 - val_loss: 2.0202 - val_accuracy: 0.3433\n",
            "Epoch 34/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0310 - accuracy: 0.3381 - val_loss: 2.0298 - val_accuracy: 0.3332\n",
            "Epoch 35/50\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 2.0282 - accuracy: 0.3405 - val_loss: 2.0238 - val_accuracy: 0.3450\n",
            "Epoch 36/50\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 2.0300 - accuracy: 0.3424 - val_loss: 2.0258 - val_accuracy: 0.3379\n",
            "Epoch 37/50\n",
            "1000/1000 [==============================] - 17s 17ms/step - loss: 2.0268 - accuracy: 0.3429 - val_loss: 2.0306 - val_accuracy: 0.3390\n",
            "Epoch 38/50\n",
            "1000/1000 [==============================] - 16s 16ms/step - loss: 2.0258 - accuracy: 0.3412 - val_loss: 2.0277 - val_accuracy: 0.3397\n",
            "Epoch 39/50\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 2.0247 - accuracy: 0.3411 - val_loss: 2.0324 - val_accuracy: 0.3375\n",
            "Epoch 40/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0286 - accuracy: 0.3412 - val_loss: 2.0279 - val_accuracy: 0.3411\n",
            "Epoch 41/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0236 - accuracy: 0.3415 - val_loss: 2.0312 - val_accuracy: 0.3389\n",
            "Epoch 42/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0269 - accuracy: 0.3380 - val_loss: 2.0324 - val_accuracy: 0.3397\n",
            "Epoch 43/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0211 - accuracy: 0.3427 - val_loss: 2.0253 - val_accuracy: 0.3420\n",
            "Epoch 44/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0202 - accuracy: 0.3438 - val_loss: 2.0384 - val_accuracy: 0.3413\n",
            "Epoch 45/50\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.0261 - accuracy: 0.3437 - val_loss: 2.0228 - val_accuracy: 0.3444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test)[1]\n",
        "print(\"Accuracy score in percentage : \" + str(round(score * 100, 2)) + \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu5Wu5V5PnPz",
        "outputId": "0abd45da-4ec0-4ee0-f57f-9944f21affc2"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 1s 5ms/step - loss: 2.0238 - accuracy: 0.3450\n",
            "Accuracy score in percentage : 34.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying a simpler Flatten/ 1D Pooling architecture"
      ],
      "metadata": {
        "id": "BdI6RNJkpLMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Embedding(vocab_size, 16, input_length = maxlen, embeddings_regularizer=l2(0.01)))\n",
        "model2.add(GlobalAveragePooling1D())\n",
        "model2.add(Dense(emotion_count, activation = 'softmax'))\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laatyNOARcjF",
        "outputId": "ae2ecc95-df1e-4f5c-b18f-a196079c7051"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_16 (Embedding)    (None, 20, 16)            481712    \n",
            "                                                                 \n",
            " global_average_pooling1d_4   (None, 16)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 13)                221       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 481,933\n",
            "Trainable params: 481,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "history = model2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=80, callbacks=[EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bAJb-AGR6uA",
        "outputId": "3a038b93-1737-4301-e831-d07381392d74"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "1000/1000 [==============================] - 5s 3ms/step - loss: 2.2848 - accuracy: 0.2204 - val_loss: 2.1601 - val_accuracy: 0.2185\n",
            "Epoch 2/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1614 - accuracy: 0.2361 - val_loss: 2.1509 - val_accuracy: 0.2320\n",
            "Epoch 3/80\n",
            "1000/1000 [==============================] - 4s 3ms/step - loss: 2.1550 - accuracy: 0.2425 - val_loss: 2.1460 - val_accuracy: 0.2344\n",
            "Epoch 4/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1507 - accuracy: 0.2441 - val_loss: 2.1419 - val_accuracy: 0.2393\n",
            "Epoch 5/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1477 - accuracy: 0.2448 - val_loss: 2.1394 - val_accuracy: 0.2438\n",
            "Epoch 6/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1455 - accuracy: 0.2461 - val_loss: 2.1388 - val_accuracy: 0.2393\n",
            "Epoch 7/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1441 - accuracy: 0.2474 - val_loss: 2.1361 - val_accuracy: 0.2429\n",
            "Epoch 8/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1430 - accuracy: 0.2472 - val_loss: 2.1352 - val_accuracy: 0.2428\n",
            "Epoch 9/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1421 - accuracy: 0.2476 - val_loss: 2.1348 - val_accuracy: 0.2428\n",
            "Epoch 10/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1417 - accuracy: 0.2467 - val_loss: 2.1346 - val_accuracy: 0.2419\n",
            "Epoch 11/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1410 - accuracy: 0.2478 - val_loss: 2.1336 - val_accuracy: 0.2467\n",
            "Epoch 12/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1406 - accuracy: 0.2463 - val_loss: 2.1334 - val_accuracy: 0.2428\n",
            "Epoch 13/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1403 - accuracy: 0.2484 - val_loss: 2.1330 - val_accuracy: 0.2428\n",
            "Epoch 14/80\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 2.1398 - accuracy: 0.2478 - val_loss: 2.1329 - val_accuracy: 0.2429\n",
            "Epoch 15/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1399 - accuracy: 0.2472 - val_loss: 2.1326 - val_accuracy: 0.2453\n",
            "Epoch 16/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1396 - accuracy: 0.2480 - val_loss: 2.1323 - val_accuracy: 0.2428\n",
            "Epoch 17/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1394 - accuracy: 0.2483 - val_loss: 2.1318 - val_accuracy: 0.2463\n",
            "Epoch 18/80\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 2.1389 - accuracy: 0.2483 - val_loss: 2.1312 - val_accuracy: 0.2454\n",
            "Epoch 19/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1386 - accuracy: 0.2486 - val_loss: 2.1311 - val_accuracy: 0.2474\n",
            "Epoch 20/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1376 - accuracy: 0.2478 - val_loss: 2.1295 - val_accuracy: 0.2466\n",
            "Epoch 21/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1367 - accuracy: 0.2485 - val_loss: 2.1298 - val_accuracy: 0.2425\n",
            "Epoch 22/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1355 - accuracy: 0.2486 - val_loss: 2.1265 - val_accuracy: 0.2466\n",
            "Epoch 23/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1341 - accuracy: 0.2495 - val_loss: 2.1271 - val_accuracy: 0.2410\n",
            "Epoch 24/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1323 - accuracy: 0.2505 - val_loss: 2.1242 - val_accuracy: 0.2454\n",
            "Epoch 25/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1307 - accuracy: 0.2512 - val_loss: 2.1218 - val_accuracy: 0.2446\n",
            "Epoch 26/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1290 - accuracy: 0.2515 - val_loss: 2.1201 - val_accuracy: 0.2484\n",
            "Epoch 27/80\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 2.1270 - accuracy: 0.2543 - val_loss: 2.1177 - val_accuracy: 0.2495\n",
            "Epoch 28/80\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 2.1253 - accuracy: 0.2567 - val_loss: 2.1160 - val_accuracy: 0.2529\n",
            "Epoch 29/80\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 2.1235 - accuracy: 0.2562 - val_loss: 2.1138 - val_accuracy: 0.2605\n",
            "Epoch 30/80\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 2.1216 - accuracy: 0.2581 - val_loss: 2.1122 - val_accuracy: 0.2612\n",
            "Epoch 31/80\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 2.1197 - accuracy: 0.2600 - val_loss: 2.1108 - val_accuracy: 0.2530\n",
            "Epoch 32/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1181 - accuracy: 0.2617 - val_loss: 2.1082 - val_accuracy: 0.2634\n",
            "Epoch 33/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1165 - accuracy: 0.2636 - val_loss: 2.1071 - val_accuracy: 0.2644\n",
            "Epoch 34/80\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 2.1148 - accuracy: 0.2647 - val_loss: 2.1047 - val_accuracy: 0.2606\n",
            "Epoch 35/80\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 2.1128 - accuracy: 0.2664 - val_loss: 2.1022 - val_accuracy: 0.2711\n",
            "Epoch 36/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1114 - accuracy: 0.2668 - val_loss: 2.0999 - val_accuracy: 0.2686\n",
            "Epoch 37/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1096 - accuracy: 0.2701 - val_loss: 2.0988 - val_accuracy: 0.2652\n",
            "Epoch 38/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1081 - accuracy: 0.2706 - val_loss: 2.0976 - val_accuracy: 0.2652\n",
            "Epoch 39/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1067 - accuracy: 0.2717 - val_loss: 2.0964 - val_accuracy: 0.2696\n",
            "Epoch 40/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1053 - accuracy: 0.2719 - val_loss: 2.0946 - val_accuracy: 0.2697\n",
            "Epoch 41/80\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 2.1037 - accuracy: 0.2724 - val_loss: 2.0929 - val_accuracy: 0.2835\n",
            "Epoch 42/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1024 - accuracy: 0.2737 - val_loss: 2.0908 - val_accuracy: 0.2731\n",
            "Epoch 43/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1009 - accuracy: 0.2749 - val_loss: 2.0898 - val_accuracy: 0.2734\n",
            "Epoch 44/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0998 - accuracy: 0.2743 - val_loss: 2.0887 - val_accuracy: 0.2783\n",
            "Epoch 45/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0985 - accuracy: 0.2763 - val_loss: 2.0865 - val_accuracy: 0.2774\n",
            "Epoch 46/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0972 - accuracy: 0.2778 - val_loss: 2.0863 - val_accuracy: 0.2735\n",
            "Epoch 47/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0960 - accuracy: 0.2774 - val_loss: 2.0845 - val_accuracy: 0.2853\n",
            "Epoch 48/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0948 - accuracy: 0.2799 - val_loss: 2.0834 - val_accuracy: 0.2765\n",
            "Epoch 49/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0935 - accuracy: 0.2801 - val_loss: 2.0820 - val_accuracy: 0.2871\n",
            "Epoch 50/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0922 - accuracy: 0.2808 - val_loss: 2.0810 - val_accuracy: 0.2797\n",
            "Epoch 51/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0911 - accuracy: 0.2828 - val_loss: 2.0795 - val_accuracy: 0.2820\n",
            "Epoch 52/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0901 - accuracy: 0.2823 - val_loss: 2.0771 - val_accuracy: 0.2820\n",
            "Epoch 53/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0892 - accuracy: 0.2831 - val_loss: 2.0782 - val_accuracy: 0.2836\n",
            "Epoch 54/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0879 - accuracy: 0.2827 - val_loss: 2.0765 - val_accuracy: 0.2824\n",
            "Epoch 55/80\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 2.0871 - accuracy: 0.2840 - val_loss: 2.0742 - val_accuracy: 0.2811\n",
            "Epoch 56/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0861 - accuracy: 0.2852 - val_loss: 2.0741 - val_accuracy: 0.2835\n",
            "Epoch 57/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0852 - accuracy: 0.2867 - val_loss: 2.0719 - val_accuracy: 0.2845\n",
            "Epoch 58/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0840 - accuracy: 0.2882 - val_loss: 2.0734 - val_accuracy: 0.2814\n",
            "Epoch 59/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0831 - accuracy: 0.2872 - val_loss: 2.0705 - val_accuracy: 0.2936\n",
            "Epoch 60/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0825 - accuracy: 0.2882 - val_loss: 2.0695 - val_accuracy: 0.2940\n",
            "Epoch 61/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0815 - accuracy: 0.2887 - val_loss: 2.0684 - val_accuracy: 0.2914\n",
            "Epoch 62/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0802 - accuracy: 0.2886 - val_loss: 2.0675 - val_accuracy: 0.2930\n",
            "Epoch 63/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0797 - accuracy: 0.2891 - val_loss: 2.0669 - val_accuracy: 0.2943\n",
            "Epoch 64/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0787 - accuracy: 0.2907 - val_loss: 2.0670 - val_accuracy: 0.2850\n",
            "Epoch 65/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0777 - accuracy: 0.2910 - val_loss: 2.0652 - val_accuracy: 0.2934\n",
            "Epoch 66/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0769 - accuracy: 0.2907 - val_loss: 2.0650 - val_accuracy: 0.2921\n",
            "Epoch 67/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0761 - accuracy: 0.2924 - val_loss: 2.0637 - val_accuracy: 0.2904\n",
            "Epoch 68/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0757 - accuracy: 0.2922 - val_loss: 2.0617 - val_accuracy: 0.2968\n",
            "Epoch 69/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0746 - accuracy: 0.2934 - val_loss: 2.0613 - val_accuracy: 0.2948\n",
            "Epoch 70/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0737 - accuracy: 0.2937 - val_loss: 2.0642 - val_accuracy: 0.2845\n",
            "Epoch 71/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0730 - accuracy: 0.2931 - val_loss: 2.0596 - val_accuracy: 0.2956\n",
            "Epoch 72/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0727 - accuracy: 0.2943 - val_loss: 2.0601 - val_accuracy: 0.2914\n",
            "Epoch 73/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0716 - accuracy: 0.2942 - val_loss: 2.0597 - val_accuracy: 0.2959\n",
            "Epoch 74/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0709 - accuracy: 0.2970 - val_loss: 2.0579 - val_accuracy: 0.2955\n",
            "Epoch 75/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0703 - accuracy: 0.2970 - val_loss: 2.0590 - val_accuracy: 0.2921\n",
            "Epoch 76/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0698 - accuracy: 0.2957 - val_loss: 2.0567 - val_accuracy: 0.2959\n",
            "Epoch 77/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0689 - accuracy: 0.2957 - val_loss: 2.0599 - val_accuracy: 0.2934\n",
            "Epoch 78/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0685 - accuracy: 0.2975 - val_loss: 2.0553 - val_accuracy: 0.2996\n",
            "Epoch 79/80\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0678 - accuracy: 0.2977 - val_loss: 2.0541 - val_accuracy: 0.2974\n",
            "Epoch 80/80\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0671 - accuracy: 0.2967 - val_loss: 2.0569 - val_accuracy: 0.2920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score2 = model2.evaluate(x_test, y_test)[1]\n",
        "print(\"Accuracy score in percentage : \" + str(round(score2 * 100, 2)) + \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td5gmkI8lvT5",
        "outputId": "2ac2d143-e52b-47fa-c19c-6b2b94c55da7"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 1s 2ms/step - loss: 2.0569 - accuracy: 0.2920\n",
            "Accuracy score in percentage : 29.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model evaluation"
      ],
      "metadata": {
        "id": "Czz3SwVEuKFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is found that with regularizers, the training progress is slow and without regularizers, the models are heavily overfitting. Further preprocessing needed, need to train for hundreds of epochs at low learning rates, and higher regularizers values\n",
        "Model 1 architecture is found to perform better"
      ],
      "metadata": {
        "id": "8QyGcfiOuM73"
      }
    }
  ]
}