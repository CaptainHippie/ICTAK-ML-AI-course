{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "UKv4SMwzNqw1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IW_MQYe3OAYB",
        "outputId": "a7be8036-fbee-4062-9784-cd4ad2934b49"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleId</th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1833</td>\n",
              "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>154</td>\n",
              "      <td>german business confidence slides german busin...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1101</td>\n",
              "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1976</td>\n",
              "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>917</td>\n",
              "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ArticleId                                               Text  Category\n",
              "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
              "1        154  german business confidence slides german busin...  business\n",
              "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
              "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
              "4        917  enron bosses in $168m payout eighteen former e...  business"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('BBC News.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoxnlYayOM1e",
        "outputId": "e8bf8d9c-3433-45a6-b11c-2553d10093cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1490, 3)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25oEeOvhOPrl",
        "outputId": "0f31bb73-e7b5-4855-d99e-e37606f63056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1490 entries, 0 to 1489\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   ArticleId  1490 non-null   int64 \n",
            " 1   Text       1490 non-null   object\n",
            " 2   Category   1490 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 35.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVbs8SirORZ5",
        "outputId": "48b30fdd-a8e2-458b-ca05-31c6b5f5ecb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sport            346\n",
              "business         336\n",
              "politics         274\n",
              "entertainment    273\n",
              "tech             261\n",
              "Name: Category, dtype: int64"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Category'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "p5p9_krvOw-F"
      },
      "outputs": [],
      "source": [
        "from gensim.utils import simple_preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "3qoxfEJwPlF3",
        "outputId": "55aa799e-ed5f-4f97-aa91-b987384ad4ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'worldcom ex-boss launches defence lawyers defending former worldcom chief bernie ebbers against a battery of fraud charges have called a company whistleblower as their first witness.  cynthia cooper  worldcom s ex-head of internal accounting  alerted directors to irregular accounting practices at the us telecoms giant in 2002. her warnings led to the collapse of the firm following the discovery of an $11bn (£5.7bn) accounting fraud. mr ebbers has pleaded not guilty to charges of fraud and conspiracy.  prosecution lawyers have argued that mr ebbers orchestrated a series of accounting tricks at worldcom  ordering employees to hide expenses and inflate revenues to meet wall street earnings estimates. but ms cooper  who now runs her own consulting business  told a jury in new york on wednesday that external auditors arthur andersen had approved worldcom s accounting in early 2001 and 2002. she said andersen had given a  green light  to the procedures and practices used by worldcom. mr ebber s lawyers have said he was unaware of the fraud  arguing that auditors did not alert him to any problems.  ms cooper also said that during shareholder meetings mr ebbers often passed over technical questions to the company s finance chief  giving only  brief  answers himself. the prosecution s star witness  former worldcom financial chief scott sullivan  has said that mr ebbers ordered accounting adjustments at the firm  telling him to  hit our books . however  ms cooper said mr sullivan had not mentioned  anything uncomfortable  about worldcom s accounting during a 2001 audit committee meeting. mr ebbers could face a jail sentence of 85 years if convicted of all the charges he is facing. worldcom emerged from bankruptcy protection in 2004  and is now known as mci. last week  mci agreed to a buyout by verizon communications in a deal valued at $6.75bn.'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdkWmYbQPzm6",
        "outputId": "acb35cb9-1f25-4f55-a6a9-fdf56921deb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['worldcom', 'ex', 'boss', 'launches', 'defence', 'lawyers', 'defending', 'former', 'worldcom', 'chief', 'bernie', 'ebbers', 'against', 'battery', 'of', 'fraud', 'charges', 'have', 'called', 'company', 'whistleblower', 'as', 'their', 'first', 'witness', 'cynthia', 'cooper', 'worldcom', 'ex', 'head']\n"
          ]
        }
      ],
      "source": [
        "print(simple_preprocess(df['Text'][0])[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "9cIa1mbjQBdD"
      },
      "outputs": [],
      "source": [
        "preprocessed_text = df['Text'].apply(lambda x: simple_preprocess(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NafnKfkZQiI_",
        "outputId": "9cb80122-941c-4f77-8085-809e11f2c664"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [worldcom, ex, boss, launches, defence, lawyer...\n",
              "1    [german, business, confidence, slides, german,...\n",
              "2    [bbc, poll, indicates, economic, gloom, citize...\n",
              "3    [lifestyle, governs, mobile, choice, faster, b...\n",
              "4    [enron, bosses, in, payout, eighteen, former, ...\n",
              "Name: Text, dtype: object"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessed_text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "bg7WyL3cQloW"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec as wtv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "aiLFug3YQ5EC"
      },
      "outputs": [],
      "source": [
        "cbow_w2v_model = wtv(preprocessed_text, vector_size=300, window=6, min_count=3, sg=0)\n",
        "skgram_w2v_model = wtv(preprocessed_text, vector_size=300, window=6, min_count=3, sg=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cbow vocalulary size: 11639\n",
            "skipgram vocalulary size: 11639\n"
          ]
        }
      ],
      "source": [
        "print(\"cbow vocalulary size:\", len(cbow_w2v_model.wv.index_to_key))\n",
        "print(\"skipgram vocalulary size:\", len(skgram_w2v_model.wv.index_to_key))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 0),\n",
              " ('to', 1),\n",
              " ('of', 2),\n",
              " ('and', 3),\n",
              " ('in', 4),\n",
              " ('for', 5),\n",
              " ('is', 6),\n",
              " ('that', 7),\n",
              " ('it', 8),\n",
              " ('on', 9),\n",
              " ('said', 10),\n",
              " ('was', 11),\n",
              " ('he', 12),\n",
              " ('be', 13),\n",
              " ('with', 14),\n",
              " ('has', 15),\n",
              " ('as', 16),\n",
              " ('have', 17),\n",
              " ('at', 18),\n",
              " ('by', 19),\n",
              " ('will', 20),\n",
              " ('but', 21),\n",
              " ('are', 22),\n",
              " ('from', 23),\n",
              " ('not', 24),\n",
              " ('they', 25),\n",
              " ('mr', 26),\n",
              " ('his', 27),\n",
              " ('an', 28),\n",
              " ('we', 29)]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(cbow_w2v_model.wv.key_to_index.items())[0:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-8.31481293e-02, -1.08959831e-01,  3.16624165e-01,  1.54434587e-03,\n",
              "       -7.74879873e-01, -1.43002719e-01,  5.98507762e-01,  1.75747007e-01,\n",
              "       -4.23971564e-01, -1.15297869e-01,  1.05543986e-01, -2.19802976e-01,\n",
              "       -2.92491969e-02, -5.98001387e-03, -3.73841748e-02,  1.61287144e-01,\n",
              "        5.89107722e-02,  1.36541739e-01, -4.71634179e-01, -8.92911926e-02,\n",
              "        6.26658350e-02,  2.89783478e-01,  2.92805254e-01,  2.22449020e-01,\n",
              "        4.36693698e-01,  1.33230031e-01,  4.77638513e-01,  1.31512150e-01,\n",
              "       -8.85784179e-02, -9.25805718e-02, -2.09146053e-01, -1.05642661e-01,\n",
              "        4.29679424e-01, -1.05261125e-01,  3.63938957e-01, -1.00621849e-01,\n",
              "        3.33613455e-01, -2.66896278e-01,  9.22922418e-02, -3.41482162e-01,\n",
              "       -6.19196534e-01, -2.74881989e-01, -1.35366306e-01,  3.06177046e-03,\n",
              "       -8.59389082e-02, -2.42521033e-01, -3.16761136e-01,  4.80453432e-01,\n",
              "        2.66053379e-01,  1.36053950e-01,  2.70124581e-02,  3.92060757e-01,\n",
              "       -4.35375243e-01, -3.44128579e-01,  6.05432615e-02, -2.84392715e-01,\n",
              "        1.85792267e-01, -5.19332647e-01,  3.08807909e-01,  1.89534560e-01,\n",
              "       -2.88624018e-01,  1.74403995e-01,  1.02405466e-01, -3.10110271e-01,\n",
              "       -3.12393904e-01,  2.77542830e-01, -2.83166438e-01,  2.99043693e-02,\n",
              "       -2.26354942e-01,  1.69878185e-01,  1.30848303e-01,  5.02552569e-01,\n",
              "        3.63195866e-01, -6.84082985e-01,  3.20804894e-01, -8.36619586e-02,\n",
              "        2.11873159e-01,  3.86077344e-01, -3.63968521e-01, -3.61642838e-02,\n",
              "       -1.66195214e-01, -7.49792308e-02,  4.45948720e-01,  8.32359135e-01,\n",
              "        1.62061870e-01,  2.31141075e-01,  2.95542330e-01,  6.46338686e-02,\n",
              "        7.21007705e-01,  4.69092727e-01,  1.50736287e-01, -1.57407373e-02,\n",
              "        5.74926853e-01, -3.43603224e-01,  6.93019450e-01,  6.26463950e-01,\n",
              "       -2.48098969e-02, -5.68706870e-01, -8.00586119e-02,  1.00243354e+00,\n",
              "       -1.12987362e-01,  6.11214399e-01, -5.55437095e-02,  2.09132001e-01,\n",
              "        2.95554310e-01, -5.24666190e-01,  1.10862695e-01,  4.04500932e-01,\n",
              "       -5.36414921e-01, -9.60293561e-02, -5.01584947e-01, -5.12956560e-01,\n",
              "        4.07363735e-02, -1.14561707e-01,  2.57811636e-01,  3.90501857e-01,\n",
              "        3.17558229e-01, -2.90058907e-02,  3.57310027e-01, -1.05664301e+00,\n",
              "        4.87224221e-01, -3.86164218e-01,  5.62528074e-02, -3.70105028e-01,\n",
              "        3.60096574e-01,  3.25710058e-01, -3.16010922e-01, -4.30547982e-01,\n",
              "       -4.02816106e-03,  5.27020395e-01,  3.69689047e-01,  4.92151290e-01,\n",
              "        2.24886745e-01, -3.07615936e-01,  2.93788433e-01,  2.82600343e-01,\n",
              "        3.53133589e-01, -5.27369678e-02, -7.51898140e-02, -9.13511589e-03,\n",
              "        3.20502132e-01, -5.25312424e-01, -3.60635161e-01,  2.73353189e-01,\n",
              "        2.57427335e-01, -3.22402194e-02, -8.44493732e-02, -5.75938635e-02,\n",
              "        1.63192704e-01, -1.76935405e-01,  1.94517881e-01, -4.19369608e-01,\n",
              "       -2.40906969e-01,  8.91872197e-02, -1.63262337e-02,  2.51311809e-01,\n",
              "        1.09999791e-01,  5.67877173e-01, -1.94887623e-01,  6.88980103e-01,\n",
              "        5.87814301e-02,  6.38989329e-01, -1.66837782e-01,  1.21635579e-01,\n",
              "        6.29232451e-02,  2.09149748e-01,  2.63677537e-01, -2.62093604e-01,\n",
              "       -1.32405341e-01,  7.71947563e-01, -1.54958919e-01,  1.21768549e-01,\n",
              "        7.37413880e-04, -2.31858522e-01, -6.84313923e-02, -2.12884098e-01,\n",
              "       -7.75392413e-01, -7.04260707e-01, -2.23119795e-01,  8.31628125e-03,\n",
              "       -8.89287665e-02,  3.72082829e-01,  7.82575607e-02, -1.79948106e-01,\n",
              "       -4.17003095e-01,  2.27104127e-01,  5.27481914e-01,  4.03226539e-02,\n",
              "        3.50736409e-01, -3.39316338e-01,  5.71545005e-01,  1.28546938e-01,\n",
              "        3.80185246e-02, -2.79305458e-01, -2.61937082e-01, -3.15333158e-01,\n",
              "        4.28935528e-01, -3.73215199e-01, -5.95132522e-02, -1.93054199e-01,\n",
              "       -1.37388945e-01, -2.45019153e-01, -5.92831075e-01, -4.71529327e-02,\n",
              "        4.55055058e-01, -1.59641039e-02, -4.39353913e-01,  1.75721824e-01,\n",
              "        1.03957705e-01,  6.52221292e-02, -3.64449084e-01, -3.15247655e-01,\n",
              "       -1.63018733e-01, -1.91016614e-01, -1.09987296e-01, -1.77198455e-01,\n",
              "        1.54237583e-01,  1.44812584e-01, -5.22272706e-01, -6.16483092e-01,\n",
              "       -2.26114653e-02,  1.93921879e-01, -3.83501351e-02, -6.45834744e-01,\n",
              "       -2.67480891e-02, -5.14259100e-01, -1.65488213e-01,  4.27637309e-01,\n",
              "       -4.92451817e-01, -6.03203429e-03,  6.45852908e-02, -2.96439141e-01,\n",
              "       -1.41725451e-01,  6.11466914e-02, -8.11973512e-01, -1.19317017e-01,\n",
              "       -1.64498284e-01,  2.34566648e-02, -8.94316733e-02, -1.95570007e-01,\n",
              "       -6.11311384e-02,  8.69261697e-02, -1.99339673e-01,  4.85149659e-02,\n",
              "        4.70284075e-01,  9.17656794e-02, -9.05571058e-02, -2.39461377e-01,\n",
              "        2.93704003e-01,  3.32365632e-01,  5.73104657e-02, -1.38362959e-01,\n",
              "       -4.51785736e-02, -4.91279662e-01, -5.92094660e-01, -1.52097419e-01,\n",
              "        1.36717796e-01,  2.97354199e-02, -5.67434251e-01, -2.41632715e-01,\n",
              "       -8.05434734e-02,  5.02280109e-02,  3.33774894e-01, -3.38742971e-01,\n",
              "       -7.22909510e-01,  4.02991772e-01,  6.27576232e-01, -1.60528734e-01,\n",
              "       -7.92566240e-01,  2.30318099e-01, -3.67947042e-01,  4.63940442e-01,\n",
              "        3.95653784e-01,  4.41798568e-01, -2.24084854e-01, -1.99771985e-01,\n",
              "        6.97567523e-01,  8.16607401e-02, -6.33180261e-01,  1.48243755e-02,\n",
              "        1.49172684e-02,  5.86358570e-02, -3.02452624e-01,  3.12219203e-01,\n",
              "       -1.77827448e-01, -6.39973760e-01, -3.11792850e-01, -9.55743715e-02,\n",
              "       -1.13881208e-01, -1.38867170e-01, -1.12106018e-01, -1.32125318e-01,\n",
              "        1.00709200e-01, -4.91553485e-01, -3.60093981e-01, -1.35394827e-01,\n",
              "        2.94675112e-01,  5.83081215e-04,  3.97491813e-01, -1.19094707e-01],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cbow_w2v_model.wv.get_vector(\"the\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('stock', 0.9794525504112244),\n",
              " ('exchange', 0.9731940031051636),\n",
              " ('profits', 0.9716687202453613),\n",
              " ('reserves', 0.9711026549339294),\n",
              " ('shares', 0.9663559198379517),\n",
              " ('india', 0.9648077487945557),\n",
              " ('surged', 0.9644091725349426),\n",
              " ('annual', 0.964008629322052),\n",
              " ('revenues', 0.9632318019866943),\n",
              " ('china', 0.9612467288970947)]"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cbow_w2v_model.wv.most_similar('oil')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('gas', 0.9029224514961243),\n",
              " ('fuel', 0.8806427717208862),\n",
              " ('currency', 0.8786510229110718),\n",
              " ('steel', 0.8776251077651978),\n",
              " ('rosneft', 0.8774250745773315),\n",
              " ('gm', 0.8729245066642761),\n",
              " ('soaring', 0.8722900152206421),\n",
              " ('telecoms', 0.8714026808738708),\n",
              " ('nestle', 0.8687661290168762),\n",
              " ('verizon', 0.8679018616676331)]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skgram_w2v_model.wv.most_similar('oil')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('networks', 0.9882583618164062),\n",
              " ('online', 0.9871498346328735),\n",
              " ('computer', 0.9865508079528809),\n",
              " ('ways', 0.9860543012619019),\n",
              " ('pc', 0.9851844906806946),\n",
              " ('operators', 0.9851817488670349),\n",
              " ('camera', 0.9851146936416626),\n",
              " ('audio', 0.9848463535308838),\n",
              " ('data', 0.9842791557312012),\n",
              " ('cameras', 0.9838600754737854)]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cbow_w2v_model.wv.most_similar('web')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('uses', 0.9186863303184509),\n",
              " ('internet', 0.8994223475456238),\n",
              " ('search', 0.8986114263534546),\n",
              " ('via', 0.8979914784431458),\n",
              " ('surfers', 0.8974375128746033),\n",
              " ('addresses', 0.8967556357383728),\n",
              " ('logs', 0.8889086246490479),\n",
              " ('text', 0.8880167603492737),\n",
              " ('programs', 0.8870521783828735),\n",
              " ('engine', 0.8818630576133728)]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skgram_w2v_model.wv.most_similar('web')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('dream', 0.9780482053756714),\n",
              " ('secures', 0.9776517152786255),\n",
              " ('liverpool', 0.9771413803100586),\n",
              " ('draw', 0.9769200682640076),\n",
              " ('tremendous', 0.9767696857452393),\n",
              " ('finish', 0.9763832688331604),\n",
              " ('highbury', 0.9763008952140808),\n",
              " ('premiership', 0.9759109020233154),\n",
              " ('referee', 0.9756413698196411),\n",
              " ('tigers', 0.9755011200904846)]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cbow_w2v_model.wv.most_similar('football')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = cbow_w2v_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_embeddimng_w2v(doc_tokens):\n",
        "    embeddings = []\n",
        "    for tok in doc_tokens:\n",
        "        if tok in model.wv.index_to_key:\n",
        "            embeddings.append(model.wv.get_vector(tok))\n",
        "    return np.mean(embeddings, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_x2v_model = preprocessed_text.apply(lambda x: get_embeddimng_w2v(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       [0.011973189, 0.19467688, -0.04046378, 0.05234...\n",
              "1       [0.0018969477, 0.09894876, 0.0024450996, 0.042...\n",
              "2       [-0.05274923, 0.061471768, 0.028618021, 0.0735...\n",
              "3       [-0.11910302, 0.09020186, 0.040273443, 0.05346...\n",
              "4       [-0.01840922, 0.0839911, 0.025732774, 0.057198...\n",
              "                              ...                        \n",
              "1485    [-0.023653498, 0.1565971, -0.030683016, 0.0250...\n",
              "1486    [-0.08261965, 0.092795834, 0.03159496, 0.04627...\n",
              "1487    [-0.0064144568, 0.100432545, -0.007991844, 0.0...\n",
              "1488    [-0.07534904, 0.032702174, 0.06799838, 0.07823...\n",
              "1489    [-0.09131403, 0.09652467, 0.045668837, 0.05301...\n",
              "Name: Text, Length: 1490, dtype: object"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_x2v_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_df = pd.DataFrame(X_x2v_model.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.011973</td>\n",
              "      <td>0.194677</td>\n",
              "      <td>-0.040464</td>\n",
              "      <td>0.052348</td>\n",
              "      <td>-0.137587</td>\n",
              "      <td>-0.141337</td>\n",
              "      <td>0.258361</td>\n",
              "      <td>0.556020</td>\n",
              "      <td>0.007281</td>\n",
              "      <td>-0.094389</td>\n",
              "      <td>...</td>\n",
              "      <td>0.059960</td>\n",
              "      <td>0.273515</td>\n",
              "      <td>0.170518</td>\n",
              "      <td>0.169251</td>\n",
              "      <td>0.234922</td>\n",
              "      <td>0.435944</td>\n",
              "      <td>0.064122</td>\n",
              "      <td>0.027693</td>\n",
              "      <td>0.115401</td>\n",
              "      <td>-0.196499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001897</td>\n",
              "      <td>0.098949</td>\n",
              "      <td>0.002445</td>\n",
              "      <td>0.042633</td>\n",
              "      <td>-0.162184</td>\n",
              "      <td>-0.089396</td>\n",
              "      <td>0.246095</td>\n",
              "      <td>0.520570</td>\n",
              "      <td>-0.060274</td>\n",
              "      <td>-0.065952</td>\n",
              "      <td>...</td>\n",
              "      <td>0.089016</td>\n",
              "      <td>0.295108</td>\n",
              "      <td>0.288690</td>\n",
              "      <td>0.110506</td>\n",
              "      <td>0.329727</td>\n",
              "      <td>0.416292</td>\n",
              "      <td>0.088499</td>\n",
              "      <td>0.038098</td>\n",
              "      <td>0.223072</td>\n",
              "      <td>-0.196864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.052749</td>\n",
              "      <td>0.061472</td>\n",
              "      <td>0.028618</td>\n",
              "      <td>0.073584</td>\n",
              "      <td>-0.109754</td>\n",
              "      <td>-0.087750</td>\n",
              "      <td>0.205602</td>\n",
              "      <td>0.571432</td>\n",
              "      <td>-0.060820</td>\n",
              "      <td>-0.071915</td>\n",
              "      <td>...</td>\n",
              "      <td>0.092383</td>\n",
              "      <td>0.319623</td>\n",
              "      <td>0.282990</td>\n",
              "      <td>0.050392</td>\n",
              "      <td>0.369795</td>\n",
              "      <td>0.421632</td>\n",
              "      <td>0.057376</td>\n",
              "      <td>-0.019114</td>\n",
              "      <td>0.217026</td>\n",
              "      <td>-0.192097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.119103</td>\n",
              "      <td>0.090202</td>\n",
              "      <td>0.040273</td>\n",
              "      <td>0.053464</td>\n",
              "      <td>-0.053153</td>\n",
              "      <td>-0.044308</td>\n",
              "      <td>0.157580</td>\n",
              "      <td>0.684285</td>\n",
              "      <td>-0.028988</td>\n",
              "      <td>-0.034751</td>\n",
              "      <td>...</td>\n",
              "      <td>0.169173</td>\n",
              "      <td>0.412378</td>\n",
              "      <td>0.299778</td>\n",
              "      <td>0.066825</td>\n",
              "      <td>0.415270</td>\n",
              "      <td>0.495610</td>\n",
              "      <td>-0.003500</td>\n",
              "      <td>-0.145262</td>\n",
              "      <td>0.246608</td>\n",
              "      <td>-0.145084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.018409</td>\n",
              "      <td>0.083991</td>\n",
              "      <td>0.025733</td>\n",
              "      <td>0.057199</td>\n",
              "      <td>-0.162890</td>\n",
              "      <td>-0.132351</td>\n",
              "      <td>0.260639</td>\n",
              "      <td>0.496307</td>\n",
              "      <td>-0.073116</td>\n",
              "      <td>-0.055969</td>\n",
              "      <td>...</td>\n",
              "      <td>0.067953</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>0.254414</td>\n",
              "      <td>0.081887</td>\n",
              "      <td>0.307588</td>\n",
              "      <td>0.381250</td>\n",
              "      <td>0.070006</td>\n",
              "      <td>0.019130</td>\n",
              "      <td>0.173927</td>\n",
              "      <td>-0.166995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1485</th>\n",
              "      <td>-0.023653</td>\n",
              "      <td>0.156597</td>\n",
              "      <td>-0.030683</td>\n",
              "      <td>0.025079</td>\n",
              "      <td>-0.131411</td>\n",
              "      <td>-0.108913</td>\n",
              "      <td>0.237678</td>\n",
              "      <td>0.564928</td>\n",
              "      <td>-0.068893</td>\n",
              "      <td>-0.113438</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066225</td>\n",
              "      <td>0.292082</td>\n",
              "      <td>0.267316</td>\n",
              "      <td>0.097349</td>\n",
              "      <td>0.327357</td>\n",
              "      <td>0.438377</td>\n",
              "      <td>0.047863</td>\n",
              "      <td>0.012529</td>\n",
              "      <td>0.124862</td>\n",
              "      <td>-0.196805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1486</th>\n",
              "      <td>-0.082620</td>\n",
              "      <td>0.092796</td>\n",
              "      <td>0.031595</td>\n",
              "      <td>0.046275</td>\n",
              "      <td>-0.085910</td>\n",
              "      <td>-0.088700</td>\n",
              "      <td>0.199786</td>\n",
              "      <td>0.626359</td>\n",
              "      <td>-0.054800</td>\n",
              "      <td>-0.072426</td>\n",
              "      <td>...</td>\n",
              "      <td>0.115426</td>\n",
              "      <td>0.364165</td>\n",
              "      <td>0.304145</td>\n",
              "      <td>0.071973</td>\n",
              "      <td>0.400452</td>\n",
              "      <td>0.484100</td>\n",
              "      <td>0.017948</td>\n",
              "      <td>-0.081957</td>\n",
              "      <td>0.200075</td>\n",
              "      <td>-0.160912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1487</th>\n",
              "      <td>-0.006414</td>\n",
              "      <td>0.100433</td>\n",
              "      <td>-0.007992</td>\n",
              "      <td>0.032878</td>\n",
              "      <td>-0.199827</td>\n",
              "      <td>-0.117580</td>\n",
              "      <td>0.313925</td>\n",
              "      <td>0.507905</td>\n",
              "      <td>-0.090025</td>\n",
              "      <td>-0.001751</td>\n",
              "      <td>...</td>\n",
              "      <td>0.130540</td>\n",
              "      <td>0.334958</td>\n",
              "      <td>0.309868</td>\n",
              "      <td>0.098606</td>\n",
              "      <td>0.371056</td>\n",
              "      <td>0.428481</td>\n",
              "      <td>0.111715</td>\n",
              "      <td>0.026015</td>\n",
              "      <td>0.235295</td>\n",
              "      <td>-0.178120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488</th>\n",
              "      <td>-0.075349</td>\n",
              "      <td>0.032702</td>\n",
              "      <td>0.067998</td>\n",
              "      <td>0.078232</td>\n",
              "      <td>-0.095765</td>\n",
              "      <td>-0.094552</td>\n",
              "      <td>0.184554</td>\n",
              "      <td>0.584113</td>\n",
              "      <td>-0.049896</td>\n",
              "      <td>-0.029715</td>\n",
              "      <td>...</td>\n",
              "      <td>0.134542</td>\n",
              "      <td>0.363558</td>\n",
              "      <td>0.299481</td>\n",
              "      <td>0.074504</td>\n",
              "      <td>0.361654</td>\n",
              "      <td>0.435818</td>\n",
              "      <td>0.028640</td>\n",
              "      <td>-0.095032</td>\n",
              "      <td>0.274516</td>\n",
              "      <td>-0.153913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1489</th>\n",
              "      <td>-0.091314</td>\n",
              "      <td>0.096525</td>\n",
              "      <td>0.045669</td>\n",
              "      <td>0.053011</td>\n",
              "      <td>-0.104612</td>\n",
              "      <td>-0.092792</td>\n",
              "      <td>0.201088</td>\n",
              "      <td>0.564678</td>\n",
              "      <td>-0.037859</td>\n",
              "      <td>-0.043760</td>\n",
              "      <td>...</td>\n",
              "      <td>0.118060</td>\n",
              "      <td>0.337866</td>\n",
              "      <td>0.269130</td>\n",
              "      <td>0.076350</td>\n",
              "      <td>0.334909</td>\n",
              "      <td>0.438405</td>\n",
              "      <td>0.034152</td>\n",
              "      <td>-0.079352</td>\n",
              "      <td>0.199001</td>\n",
              "      <td>-0.143814</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1490 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0     0.011973  0.194677 -0.040464  0.052348 -0.137587 -0.141337  0.258361   \n",
              "1     0.001897  0.098949  0.002445  0.042633 -0.162184 -0.089396  0.246095   \n",
              "2    -0.052749  0.061472  0.028618  0.073584 -0.109754 -0.087750  0.205602   \n",
              "3    -0.119103  0.090202  0.040273  0.053464 -0.053153 -0.044308  0.157580   \n",
              "4    -0.018409  0.083991  0.025733  0.057199 -0.162890 -0.132351  0.260639   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1485 -0.023653  0.156597 -0.030683  0.025079 -0.131411 -0.108913  0.237678   \n",
              "1486 -0.082620  0.092796  0.031595  0.046275 -0.085910 -0.088700  0.199786   \n",
              "1487 -0.006414  0.100433 -0.007992  0.032878 -0.199827 -0.117580  0.313925   \n",
              "1488 -0.075349  0.032702  0.067998  0.078232 -0.095765 -0.094552  0.184554   \n",
              "1489 -0.091314  0.096525  0.045669  0.053011 -0.104612 -0.092792  0.201088   \n",
              "\n",
              "           7         8         9    ...       290       291       292  \\\n",
              "0     0.556020  0.007281 -0.094389  ...  0.059960  0.273515  0.170518   \n",
              "1     0.520570 -0.060274 -0.065952  ...  0.089016  0.295108  0.288690   \n",
              "2     0.571432 -0.060820 -0.071915  ...  0.092383  0.319623  0.282990   \n",
              "3     0.684285 -0.028988 -0.034751  ...  0.169173  0.412378  0.299778   \n",
              "4     0.496307 -0.073116 -0.055969  ...  0.067953  0.279070  0.254414   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1485  0.564928 -0.068893 -0.113438  ...  0.066225  0.292082  0.267316   \n",
              "1486  0.626359 -0.054800 -0.072426  ...  0.115426  0.364165  0.304145   \n",
              "1487  0.507905 -0.090025 -0.001751  ...  0.130540  0.334958  0.309868   \n",
              "1488  0.584113 -0.049896 -0.029715  ...  0.134542  0.363558  0.299481   \n",
              "1489  0.564678 -0.037859 -0.043760  ...  0.118060  0.337866  0.269130   \n",
              "\n",
              "           293       294       295       296       297       298       299  \n",
              "0     0.169251  0.234922  0.435944  0.064122  0.027693  0.115401 -0.196499  \n",
              "1     0.110506  0.329727  0.416292  0.088499  0.038098  0.223072 -0.196864  \n",
              "2     0.050392  0.369795  0.421632  0.057376 -0.019114  0.217026 -0.192097  \n",
              "3     0.066825  0.415270  0.495610 -0.003500 -0.145262  0.246608 -0.145084  \n",
              "4     0.081887  0.307588  0.381250  0.070006  0.019130  0.173927 -0.166995  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "1485  0.097349  0.327357  0.438377  0.047863  0.012529  0.124862 -0.196805  \n",
              "1486  0.071973  0.400452  0.484100  0.017948 -0.081957  0.200075 -0.160912  \n",
              "1487  0.098606  0.371056  0.428481  0.111715  0.026015  0.235295 -0.178120  \n",
              "1488  0.074504  0.361654  0.435818  0.028640 -0.095032  0.274516 -0.153913  \n",
              "1489  0.076350  0.334909  0.438405  0.034152 -0.079352  0.199001 -0.143814  \n",
              "\n",
              "[1490 rows x 300 columns]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "df['Category'] = le.fit_transform(df['Category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_df, df['Category'], test_size=0.2, random_state=134)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gnb = GaussianNB()\n",
        "gnb.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_gnb = gnb.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7684563758389261"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test, y_pred_gnb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Google word2vec pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
